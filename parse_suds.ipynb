{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635f1123-701c-42ca-a758-ffd5fb37e7f7",
   "metadata": {},
   "source": [
    "# Converting PC-SUDS to MiniSEED — What We Actually Learned\n",
    "\n",
    "This project produced what is likely the first modern, open-source **PC-SUDS → MiniSEED** converter in Python.  \n",
    "To do that, we had to reverse-engineer how **modern EchoPro and Gecko digitizers write SUDS files**, which differ significantly from the 1990s-era SRC specification.\n",
    "\n",
    "This document summarises the *actual* structure of the files and the logic required to extract waveforms and metadata reliably.\n",
    "\n",
    "---\n",
    "\n",
    "# 1. **SUDS File Structure (EchoPro / Gecko)**\n",
    "\n",
    "Every SUDS block begins with a **12-byte STRUCTAG**:\n",
    "\n",
    "| Bytes | Meaning |\n",
    "|------|---------|\n",
    "| 0 | `'S'` sync |\n",
    "| 1 | `'6'` machine ID |\n",
    "| 2–3 | struct ID (`uint16`) |\n",
    "| 4–7 | struct length (`uint32`) |\n",
    "| 8–11 | data length (`uint32`) |\n",
    "\n",
    "A full block looks like:\n",
    "\n",
    "```\n",
    "[STRUCTAG][STRUCT_BODY][DATA_BODY]\n",
    "```\n",
    "\n",
    "In real digitizer files (EchoPro, Gecko), the only struct types that appear are:\n",
    "\n",
    "| ID | Struct Type |\n",
    "|----|-------------|\n",
    "| **5** | STATIONCOMP |\n",
    "| **7** | DESCRIPTRACE |\n",
    "| **20** | COMMENT |\n",
    "| *(everything else absent)* |\n",
    "\n",
    "Notably missing in modern SUDS files:\n",
    "\n",
    "❌ **SUDS_INSTRUMENT (ID 6)**  \n",
    "❌ Indexes, triggers, site structures  \n",
    "❌ Per-instrument response tables  \n",
    "\n",
    "Modern firmware simply does not emit these struct types.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. **Where Metadata Actually Lives**\n",
    "\n",
    "## ✔ A. STATIONCOMP (ID = 5) — the main metadata block\n",
    "\n",
    "This contains:\n",
    "\n",
    "- latitude / longitude / elevation  \n",
    "- component code  \n",
    "- channel number  \n",
    "- sensor type (`v`, `a`, etc.)  \n",
    "- data type (`i`, `l`, `f`)  \n",
    "- data units  \n",
    "- polarity  \n",
    "- **A/D gain** (`atod_gain`)  \n",
    "- **start epoch** (effective time)  \n",
    "\n",
    "This is the **correct** source for station and channel identity.\n",
    "\n",
    "### Important  \n",
    "STATIONCOMP contains **A/D gain**, but *not* the recorder’s “counts per volt” calibration and *not* the sensor’s volts-per-unit sensitivity.  \n",
    "Those live outside the SUDS struct system.\n",
    "\n",
    "---\n",
    "\n",
    "## ✔ B. DESCRIPTRACE (ID = 7) — waveform header + waveform data\n",
    "\n",
    "Earlier we thought DESCRIPTRACE headers were empty — that was wrong.  \n",
    "We now know that DESCRIPTRACE reliably contains:\n",
    "\n",
    "- `begintime` (converted from FLOAT64 → epoch ms → epoch seconds)  \n",
    "- `length` – exact number of samples  \n",
    "- `rate` – the **correct sampling rate**  \n",
    "- `datatype` – `'i'`, `'l'`, `'2'`, `'f'`  \n",
    "- waveform min/max values  \n",
    "- some gain correction floats  \n",
    "- number of clipped samples  \n",
    "- and then the **raw sample array**\n",
    "\n",
    "### Why DESCRIPTRACE is essential\n",
    "It provides **the correct:**\n",
    "\n",
    "- start time  \n",
    "- sample rate  \n",
    "- number of samples  \n",
    "\n",
    "and replaces the old “assume 60-second files” logic completely.\n",
    "\n",
    "---\n",
    "\n",
    "## ✔ C. COMMENT (ID = 20)\n",
    "\n",
    "EchoPro writes rich text blocks:\n",
    "\n",
    "```\n",
    "DataLogger=Echo Pro\n",
    "Battery Voltage=10.76\n",
    "SensorA=Guralp CMG-6T-1\n",
    "SensorASerial=66532\n",
    "SensorB=Guralp CMG-5T-2g\n",
    "...\n",
    "```\n",
    "\n",
    "This is valuable operational metadata, but *not* response information.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. **The Critical Discovery: Recorder & Sensor Sensitivity Are Not in Any SUDS Struct**\n",
    "\n",
    "This is the biggest practical insight from the reverse-engineering effort.\n",
    "\n",
    "| Quantity | Where it actually lives |\n",
    "|---------|--------------------------|\n",
    "| **Recorder sensitivity (counts per volt)** | float32 @ **absolute offset 156** |\n",
    "| **Sensor sensitivity (volts per unit)** | float32 @ **absolute offset 176** |\n",
    "| **Neither belongs to any SUDS struct** | ✔ correct |\n",
    "\n",
    "Examples found in real files:\n",
    "\n",
    "### Recorder sensitivity\n",
    "- Gecko: **419430.4**  \n",
    "- EchoPro: **838860.8**\n",
    "\n",
    "### Sensor sensitivity\n",
    "- HML1 accelerometer: **1010.0**  \n",
    "- LOCU velocimeter: **2400.0**  \n",
    "- STBK accelerometer: **750.0**\n",
    "\n",
    "These values were stable across many files.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. **Waveform Extraction (Final, Correct Logic)**\n",
    "\n",
    "We now use:\n",
    "\n",
    "- **DESCRIPTRACE.rate** → sample rate  \n",
    "- **DESCRIPTRACE.length** → number of samples  \n",
    "- **STATIONCOMP.start_epoch** → start time  \n",
    "- **STATIONCOMP.metadata** → channel identity  \n",
    "- **raw `len_data`** → bytes to read  \n",
    "- **datatype** → sample width  \n",
    "\n",
    "This is robust for all tested digitizers and file variants.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. **Limitations of the SUDS Format (Based on Real Files)**\n",
    "\n",
    "### ❌ No SEED location codes  \n",
    "We must supply `\"00\"`, `\"60\"`, etc., externally.\n",
    "\n",
    "### ❌ No instrument response information  \n",
    "EchoPro/Gecko store only:\n",
    "- counts-per-volt (offset 156)\n",
    "- volts-per-unit (offset 176)\n",
    "\n",
    "### ❌ Channels often have non-SEED names  \n",
    "Could be:\n",
    "- `E/N/Z`\n",
    "- `CHE/CHN/CHZ`\n",
    "- `c01/c02/c03`\n",
    "\n",
    "User mapping is unavoidable.\n",
    "\n",
    "### ❌ Older SUDS structures (INSTRUMENT, ARRAY, etc.) are **never** present  \n",
    "Modern firmware does not write them.\n",
    "\n",
    "---\n",
    "\n",
    "# 6. **Summary**\n",
    "\n",
    "- Modern digitizers produce a **minimal**, consistent subset of SUDS.\n",
    "- Only three struct types appear:\n",
    "  - **STATIONCOMP (ID 5)** — metadata  \n",
    "  - **DESCRIPTRACE (ID 7)** — waveform header + samples  \n",
    "  - **COMMENT (ID 20)** — text metadata  \n",
    "- Recorder and sensor sensitivities live **outside** all structs, at fixed offsets.\n",
    "- DESCRIPTRACE gives correct sample rate, correct sample count, and correct start time.\n",
    "- STATIONCOMP gives correct channel/station metadata.\n",
    "- Result: a fully functional, reliable PC-SUDS → MiniSEED converter in Python.\n",
    "\n",
    "This gives us a transparent, reproducible extraction workflow — and replaces the often-misleading Java code with a clean, modern implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cc2b2be-9f59-4049-bcd0-7c8a1eaec6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from obspy import Trace, Stream, UTCDateTime\n",
    "from dataclasses import dataclass, field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2929fb47-c127-40bb-a960-da39c8ad53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. STATIONCOMP (unchanged from your \"locked in\" version)\n",
    "# ============================================================\n",
    "def parse_stationcomp_struct(raw, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Parse a SUDS_STATIONCOMP struct of length 108 bytes\n",
    "    (STATIDENT + STATIONCOMP guts + LONGIDENT) as per SRC Java.\n",
    "\n",
    "    Returns a metadata dict with keys:\n",
    "        network, station, location, channel_name, channel_number,\n",
    "        component_char, data_type, start_epoch, latitude, longitude,\n",
    "        elevation, atod_gain, sensor_type, data_units, polarity.\n",
    "    \"\"\"\n",
    "    if len(raw) != 108:\n",
    "        raise ValueError(f\"Expected 108 bytes for STATIONCOMP, got {len(raw)}\")\n",
    "\n",
    "    # --- STATIDENT (0–11) ---\n",
    "    statident = raw[0:12]\n",
    "    net_short = statident[0:4].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    sta_short = statident[4:9].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    comp_char = statident[9:10].decode(\"ascii\", errors=\"ignore\")\n",
    "\n",
    "    # --- STATIONCOMP guts (12–75, 64 bytes) ---\n",
    "    sc = raw[12:76]\n",
    "\n",
    "    lat = struct.unpack(\"<d\", sc[4:12])[0]\n",
    "    lon = struct.unpack(\"<d\", sc[12:20])[0]\n",
    "    elev = struct.unpack(\"<f\", sc[20:24])[0]\n",
    "\n",
    "    sensor_type = sc[31:32].decode(\"ascii\", errors=\"ignore\")\n",
    "    data_type = sc[32:33].decode(\"ascii\", errors=\"ignore\")   # 'i', 'l', '2', 'f', ...\n",
    "    data_units = sc[33:34].decode(\"ascii\", errors=\"ignore\")\n",
    "    polarity = sc[34:35].decode(\"ascii\", errors=\"ignore\")\n",
    "\n",
    "    channel_num = struct.unpack(\"<h\", sc[48:50])[0]\n",
    "    atod_gain = struct.unpack(\"<h\", sc[50:52])[0]\n",
    "\n",
    "    effective_val = struct.unpack(\"<i\", sc[52:56])[0]\n",
    "    # These files use seconds since Unix epoch\n",
    "    if 1_000_000_000 < effective_val < 2_200_000_000:\n",
    "        start_epoch = effective_val\n",
    "    else:\n",
    "        start_epoch = None\n",
    "\n",
    "    # --- LONGIDENT (76–107, 32 bytes) ---\n",
    "    li = raw[76:108]\n",
    "    net_long = li[0:8].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    sta_long = li[8:24].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    comp_long = li[24:32].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "\n",
    "    # Prefer LONGIDENT if present\n",
    "    network = net_long or net_short\n",
    "    station = sta_long or sta_short\n",
    "    channel_name = comp_long or comp_char  # 'CHE', 'CHZ', 'CHN', 'c01', …\n",
    "\n",
    "    # Location code: SUDS has none → use mapping, else '00'\n",
    "    if station_to_loc is not None and station in station_to_loc:\n",
    "        location = station_to_loc[station]\n",
    "    else:\n",
    "        location = \"00\"\n",
    "\n",
    "    return {\n",
    "        \"network\": network,\n",
    "        \"station\": station,\n",
    "        \"location\": location,\n",
    "        \"channel_name\": channel_name,\n",
    "        \"channel_number\": channel_num,\n",
    "        \"component_char\": comp_char,\n",
    "        \"data_type\": data_type,\n",
    "        \"start_epoch\": start_epoch,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"elevation\": elev,\n",
    "        \"atod_gain\": atod_gain,\n",
    "        \"sensor_type\": sensor_type,\n",
    "        \"data_units\": data_units,\n",
    "        \"polarity\": polarity,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. DESCRIPTRACE parser (uses layout from Java + your hexdump)\n",
    "# ============================================================\n",
    "def _parse_descriptrace_struct(raw):\n",
    "    \"\"\"\n",
    "    Parse SUDS_DESCRIPTRACE \"guts\" *after* STATIDENT.\n",
    "\n",
    "    Layout inside the struct (after 12-byte STATIDENT):\n",
    "\n",
    "      double begintime       (8 bytes)  [seconds since epoch in your files]\n",
    "      short  localtime       (2)\n",
    "      char   datatype        (1)        'i', 'l', '2', 'f'\n",
    "      char   descriptor      (1)\n",
    "      short  digi_by         (2)\n",
    "      short  processed       (2)\n",
    "      int    length          (4)        # samples\n",
    "      float  rate            (4)        Hz\n",
    "      float  mindata         (4)\n",
    "      float  maxdata         (4)\n",
    "      float  avenoise        (4)\n",
    "      int    numclip         (4)\n",
    "      double time_correct    (8)\n",
    "      float  rate_correct    (4)\n",
    "\n",
    "    We only actually *need*:\n",
    "      begintime, datatype, length, rate\n",
    "    \"\"\"\n",
    "    if len(raw) < 12 + 8 + 2 + 1 + 1 + 2 + 2 + 4 + 4:\n",
    "        raise ValueError(\"DESCRIPTRACE struct too short\")\n",
    "\n",
    "    pos = 12  # skip STATIDENT\n",
    "\n",
    "    begintime_sec = struct.unpack_from(\"<d\", raw, pos)[0]\n",
    "    pos += 8\n",
    "\n",
    "    localtime = struct.unpack_from(\"<h\", raw, pos)[0]\n",
    "    pos += 2\n",
    "\n",
    "    datatype = struct.unpack_from(\"<c\", raw, pos)[0].decode(\"ascii\", errors=\"ignore\")\n",
    "    pos += 1\n",
    "\n",
    "    descriptor = struct.unpack_from(\"<c\", raw, pos)[0].decode(\"ascii\", errors=\"ignore\")\n",
    "    pos += 1\n",
    "\n",
    "    digi_by = struct.unpack_from(\"<h\", raw, pos)[0]\n",
    "    pos += 2\n",
    "\n",
    "    processed = struct.unpack_from(\"<h\", raw, pos)[0]\n",
    "    pos += 2\n",
    "\n",
    "    length = struct.unpack_from(\"<i\", raw, pos)[0]\n",
    "    pos += 4\n",
    "\n",
    "    rate = struct.unpack_from(\"<f\", raw, pos)[0]\n",
    "    pos += 4\n",
    "\n",
    "    # We could read the rest, but we don't need it here.\n",
    "\n",
    "    return {\n",
    "        \"begintime_sec\": begintime_sec,\n",
    "        \"datatype\": datatype,\n",
    "        \"length\": length,\n",
    "        \"rate\": rate,\n",
    "        \"localtime\": localtime,\n",
    "        \"digi_by\": digi_by,\n",
    "        \"processed\": processed,\n",
    "        \"descriptor\": descriptor,\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_instrument_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_INSTRUMENT (ID=10).\n",
    "    Returns dict with instrument response parameters.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_phasepick_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_PHS (ID=20).\n",
    "    Returns dict with station, channel, pick time, phase type, residual, etc.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_study_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_STUDY (ID=27).\n",
    "    Returns dict with study/project information.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_longident_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_LONGIDENT (ID=31).\n",
    "    Extended station ID.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_hypo_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_HYPO (ID=32).\n",
    "    Returns dict:\n",
    "        {\n",
    "          \"origin_time\": ...,\n",
    "          \"latitude\": ...,\n",
    "          \"longitude\": ...,\n",
    "          \"depth_km\": ...,\n",
    "          \"magnitude\": ...,\n",
    "          \"errors\": {...}\n",
    "        }\n",
    "    \"\"\"\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96247111-90b4-42c0-b22f-cd4e14314c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e20f3b52-127a-431f-968a-e6c645ac6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 3. Waveform extraction — now using DESCRIPTRACE.rate/length\n",
    "# ============================================================\n",
    "def extract_waveforms_with_metadata(path, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Extract all waveforms from a SUDS file and attach metadata derived\n",
    "    from STATIONCOMP + DESCRIPTRACE.\n",
    "\n",
    "    Returns a list of dicts with keys:\n",
    "        network, station, location, channel,\n",
    "        start_epoch, samprate, latitude, longitude, elevation, data (np.float32).\n",
    "    \"\"\"\n",
    "    waves = []\n",
    "    meta = None  # last STATIONCOMP for pairing\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            tag_raw = f.read(12)\n",
    "            if len(tag_raw) < 12:\n",
    "                break\n",
    "\n",
    "            sync, mach, id_struct, len_struct, len_data = struct.unpack(\"<ccHII\", tag_raw)\n",
    "            if sync != b\"S\" or mach != b\"6\":\n",
    "                raise RuntimeError(f\"Bad SUDS tag sync/machine in {path}\")\n",
    "\n",
    "            struct_bytes = f.read(len_struct)\n",
    "            data_bytes = f.read(len_data) if len_data > 0 else b\"\"\n",
    "\n",
    "            # --- STATIONCOMP (metadata per channel) ---\n",
    "            if id_struct == 5:\n",
    "                try:\n",
    "                    meta = parse_stationcomp_struct(struct_bytes, station_to_loc=station_to_loc)\n",
    "                except Exception:\n",
    "                    meta = None\n",
    "                continue\n",
    "\n",
    "            # --- DESCRIPTRACE (waveform header + samples) ---\n",
    "            if id_struct == 7:\n",
    "                if meta is None:\n",
    "                    # No matching STATIONCOMP; skip waveform safely\n",
    "                    continue\n",
    "\n",
    "                # First try to parse DESCRIPTRACE header\n",
    "                desc = None\n",
    "                try:\n",
    "                    desc = _parse_descriptrace_struct(struct_bytes)\n",
    "                except Exception:\n",
    "                    desc = None\n",
    "\n",
    "                # Decide datatype\n",
    "                if desc is not None and desc[\"datatype\"] in (\"i\", \"l\", \"2\", \"f\"):\n",
    "                    dt = desc[\"datatype\"]\n",
    "                else:\n",
    "                    dt = meta[\"data_type\"]\n",
    "\n",
    "                # Map datatype -> bytes/sample, numpy dtype\n",
    "                if dt == \"i\":\n",
    "                    bps = 2\n",
    "                    np_dt = \"<i2\"\n",
    "                elif dt in (\"l\", \"2\"):\n",
    "                    bps = 4\n",
    "                    np_dt = \"<i4\"\n",
    "                elif dt == \"f\":\n",
    "                    bps = 4\n",
    "                    np_dt = \"<f4\"\n",
    "                else:\n",
    "                    # Unknown type: skip this waveform\n",
    "                    continue\n",
    "\n",
    "                total_samples = len(data_bytes) // bps\n",
    "\n",
    "                # Prefer DESCRIPTRACE.length if sane, else fall back to all bytes\n",
    "                if desc is not None and 0 < desc[\"length\"] <= total_samples:\n",
    "                    nsamp = desc[\"length\"]\n",
    "                else:\n",
    "                    nsamp = total_samples\n",
    "\n",
    "                # Prefer DESCRIPTRACE.rate if sane, else derive from nsamp/duration if you want\n",
    "                if desc is not None and desc[\"rate\"] > 0:\n",
    "                    samprate = float(desc[\"rate\"])\n",
    "                else:\n",
    "                    # Fallback: crude guess (1-minute files). You can tweak if needed.\n",
    "                    samprate = float(nsamp) / 60.0 if nsamp > 0 else 0.0\n",
    "\n",
    "                # Read exactly nsamp samples\n",
    "                nbytes = nsamp * bps\n",
    "                data = np.frombuffer(data_bytes[:nbytes], dtype=np_dt).astype(\"float32\")\n",
    "\n",
    "                waves.append({\n",
    "                # --- High-level waveform info ---\n",
    "                \"network\": meta[\"network\"],\n",
    "                \"station\": meta[\"station\"],\n",
    "                \"location\": meta[\"location\"],\n",
    "                \"channel\": meta[\"channel_name\"],     # ObsPy channel code\n",
    "                \"start_epoch\": meta[\"start_epoch\"],\n",
    "                \"samprate\": samprate,\n",
    "                \"data\": data,\n",
    "            \n",
    "                # --- Coordinates ---\n",
    "                \"latitude\": meta[\"latitude\"],\n",
    "                \"longitude\": meta[\"longitude\"],\n",
    "                \"elevation\": meta[\"elevation\"],\n",
    "            \n",
    "                # --- Channel-level metadata from STATIONCOMP ---\n",
    "                \"channel_number\": meta[\"channel_number\"],\n",
    "                \"component_char\": meta[\"component_char\"],\n",
    "                \"sensor_type\": meta[\"sensor_type\"],      # 'v', 'a', etc\n",
    "                \"data_type\": meta[\"data_type\"],          # 'i', 'l', '2', 'f'\n",
    "                \"data_units\": meta[\"data_units\"],        # usually 'd'\n",
    "                \"polarity\": meta[\"polarity\"],            # 'n' or 'r'\n",
    "                \"atod_gain\": meta[\"atod_gain\"],          # REAL value!\n",
    "            })\n",
    "\n",
    "            # All other struct types are ignored here\n",
    "\n",
    "    return waves\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Stream builder (unchanged interface)\n",
    "# ============================================================\n",
    "def suds_file_to_stream(path, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Parse a SUDS file and return an ObsPy Stream with one Trace per component.\n",
    "    \"\"\"\n",
    "    waves = extract_waveforms_with_metadata(path, station_to_loc=station_to_loc)\n",
    "\n",
    "    traces = []\n",
    "    for w in waves:\n",
    "        if w[\"start_epoch\"] is None:\n",
    "            raise RuntimeError(f\"No valid start_epoch found for file {path}\")\n",
    "\n",
    "        tr = Trace(\n",
    "            data=w[\"data\"],\n",
    "            header={\n",
    "                \"network\": w[\"network\"],\n",
    "                \"station\": w[\"station\"],\n",
    "                \"location\": w[\"location\"],\n",
    "                \"channel\": w[\"channel\"],\n",
    "                \"starttime\": UTCDateTime(w[\"start_epoch\"]),\n",
    "                \"sampling_rate\": w[\"samprate\"],\n",
    "            },\n",
    "        )\n",
    "        traces.append(tr)\n",
    "\n",
    "    return Stream(traces=traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe9b8f-5657-48b0-8cba-a73992bdb2eb",
   "metadata": {},
   "source": [
    "## test of read stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "baae7af6-706d-4c32-be3e-373169b646bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "VW.LOCU.00.CHE | 2025-12-09T04:50:00.000000Z - 2025-12-09T04:50:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.LOCU.00.CHN | 2025-12-09T04:50:00.000000Z - 2025-12-09T04:50:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.LOCU.00.CHZ | 2025-12-09T04:50:00.000000Z - 2025-12-09T04:50:59.996000Z | 250.0 Hz, 15000 samples\n"
     ]
    }
   ],
   "source": [
    "st = suds_file_to_stream(\"data/20251209_0450_LOCU.seismosphere.sud\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2994ef43-f41e-4900-828b-bb3e5c2f240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "VW.TRPU.00.CHE | 2025-12-08T05:00:00.000000Z - 2025-12-08T05:00:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.TRPU.00.CHZ | 2025-12-08T05:00:00.000000Z - 2025-12-08T05:00:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.TRPU.00.CHN | 2025-12-08T05:00:00.000000Z - 2025-12-08T05:00:59.996000Z | 250.0 Hz, 15000 samples\n"
     ]
    }
   ],
   "source": [
    "st = suds_file_to_stream(\"data/20251208_0500_TRPU.seismosphere.sud\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38b0d91f-783b-4c77-9ffb-1f858beefd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.0\n",
      "250.0\n",
      "250.0\n"
     ]
    }
   ],
   "source": [
    "for tr in st:\n",
    "    print(tr.stats['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9acdd38d-b449-4258-9425-5aa0078409ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Trace(s) in Stream:\n",
      "\n",
      "S1.AUSMG.00.HHZ | 2025-12-05T09:51:59.000000Z - 2025-12-05T09:54:59.590000Z | 100.0 Hz, 18060 samples\n",
      "...\n",
      "(61 other traces)\n",
      "...\n",
      "OZ.FRTM.00.HHZ | 2025-12-05T09:52:00.000000Z - 2025-12-05T09:55:00.000000Z | 100.0 Hz, 18001 samples\n",
      "\n",
      "[Use \"print(Stream.__str__(extended=True))\" to print all Traces]\n"
     ]
    }
   ],
   "source": [
    "st = suds_file_to_stream(\"data/2025-12-05 0952 Mansfield Vic.dmx\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57f70137-f50a-40ea-b2e4-55f6fc5269ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "200.0\n",
      "100.0\n",
      "40.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "200.0\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "for tr in st:\n",
    "    print(tr.stats['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742c308-288a-4dae-bc49-adee7352b1b6",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08ea2d61-2166-482b-803d-06f26138aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import struct\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class SudsComment:\n",
    "    refer: int\n",
    "    item: int\n",
    "    length: int\n",
    "    text: str\n",
    "    struct_offset: int\n",
    "\n",
    "def _decode_suds_comment(struct_buf: bytes, data_buf: bytes, offset: int) -> SudsComment:\n",
    "    refer, item, length, unused = struct.unpack(\"<hhhh\", struct_buf)\n",
    "    text = data_buf.decode(\"utf-8\", errors=\"replace\")\n",
    "    return SudsComment(refer, item, length, text, offset)\n",
    "\n",
    "def parse_suds_comments(path: str) -> List[SudsComment]:\n",
    "    COMMENT_ID = 20\n",
    "    comments = []\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        offset = 0\n",
    "        while True:\n",
    "            tag_raw = f.read(12)\n",
    "            if len(tag_raw) < 12:\n",
    "                break\n",
    "\n",
    "            sync, machine, id_struct, len_struct, len_data = struct.unpack(\"<ccHII\", tag_raw)\n",
    "            if sync != b\"S\" or machine != b\"6\":\n",
    "                break\n",
    "\n",
    "            struct_buf = f.read(len_struct)\n",
    "            data_buf = f.read(len_data) if len_data else b\"\"\n",
    "\n",
    "            if id_struct == COMMENT_ID:\n",
    "                comments.append(\n",
    "                    _decode_suds_comment(struct_buf, data_buf, offset)\n",
    "                )\n",
    "\n",
    "            offset += 12 + len_struct + len_data\n",
    "\n",
    "    return comments\n",
    "\n",
    "\n",
    "def read_float32_at_offset(path, offset):\n",
    "    \"\"\"\n",
    "    Read a little-endian float32 from absolute byte offset in a file.\n",
    "    Returns the float value or None if out of range.\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        f.seek(0, 2)\n",
    "        size = f.tell()\n",
    "        if offset + 4 > size:\n",
    "            return None\n",
    "        f.seek(offset)\n",
    "        data = f.read(4)\n",
    "    return struct.unpack(\"<f\", data)[0]\n",
    "\n",
    "\n",
    "\n",
    "def suds_file_metadata(path, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Clean consolidated metadata structure.\n",
    "    Returns:\n",
    "      {\n",
    "        \"recorder\": { ... },\n",
    "        \"station\": { ... }\n",
    "      }\n",
    "    \"\"\"\n",
    "    # ---- 1. Recorder-level values ----\n",
    "    recorder_sens = read_float32_at_offset(path, 156)\n",
    "    sensor_sens   = read_float32_at_offset(path, 176)\n",
    "    comments      = parse_suds_comments(path)\n",
    "    comment       = comments[0] if comments else None\n",
    "\n",
    "    # ---- 2. Station + channel metadata ----\n",
    "    waves = extract_waveforms_with_metadata(path, station_to_loc=station_to_loc)\n",
    "\n",
    "    if not waves:\n",
    "        raise RuntimeError(\"No STATIONCOMP/trace metadata found\")\n",
    "\n",
    "    # All channels have same station coordinates\n",
    "    w0 = waves[0]\n",
    "\n",
    "    station_meta = {\n",
    "        \"network\": w0[\"network\"],\n",
    "        \"station\": w0[\"station\"],\n",
    "        \"location\": w0[\"location\"],\n",
    "        \"latitude_deg\": w0[\"latitude\"],\n",
    "        \"longitude_deg\": w0[\"longitude\"],\n",
    "        \"elevation_m\": w0[\"elevation\"],\n",
    "        \"channels\": {}\n",
    "    }\n",
    "\n",
    "    # Move atod_gain to recorder-level\n",
    "    atod_gain = w0[\"atod_gain\"]\n",
    "\n",
    "    for w in waves:\n",
    "        station_meta[\"channels\"][w[\"channel\"]] = {\n",
    "            \"channel_number\": w[\"channel_number\"],\n",
    "            \"component\": w[\"component_char\"],\n",
    "            \"sensor_type\": w[\"sensor_type\"],\n",
    "            \"data_type\": w[\"data_type\"],\n",
    "            \"data_units\": w[\"data_units\"],\n",
    "            \"polarity\": w[\"polarity\"],\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"recorder\": {\n",
    "            \"recorder_sensitivity_counts_per_volt\": recorder_sens,\n",
    "            \"sensor_sensitivity_volts_per_unit\": sensor_sens,\n",
    "            \"atod_gain\": atod_gain,\n",
    "            \"comment\": comment,\n",
    "        },\n",
    "        \"station\": station_meta,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87073419-13a0-4832-8373-efff23a5e25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaadf92-1340-4351-9b1b-6c7e4402a84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c95e8-a16a-4de4-8092-823abb4ef033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ad315-7794-42e3-b96e-547dc4b69e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2fb77726-cd90-4f65-8231-ea39d3ea1e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recorder': {'recorder_sensitivity_counts_per_volt': 838860.8125,\n",
       "  'sensor_sensitivity_volts_per_unit': 1010.0,\n",
       "  'atod_gain': 1,\n",
       "  'comment': SudsComment(refer=-32767, item=-32767, length=446, text='DataLogger=Echo Pro\\nBattery Voltage=10.76\\nSupply Current=0.41\\nCharger Current=-1.0\\nTotal Bytes=4182016\\nPercent Free=95.0\\nTemperature=35.0\\nSync Time=20251208 0500 18.0\\nSync=0.0\\nTime OK\\nUTC=2025-12-08 0501 18\\nLOC=2025-12-08 0501 18 (UTC+0)\\nSensorA=Guralp CMG-6T-1 seismometer\\nSensorASerial=66532\\nSensorB=Guralp 2g CMG-5T accelerometer\\nSensorBSerial=5221\\n\\nSTA time=0.0\\nLTA time=0.0\\nFilter 0.0 0.0\\nNormalizingFactor=1.00000e+00\\nSensorSensitivity=0.0\\n', struct_offset=12354)},\n",
       " 'station': {'network': 'AB',\n",
       "  'station': 'HML1',\n",
       "  'location': '00',\n",
       "  'latitude_deg': -34.403350830078125,\n",
       "  'longitude_deg': 138.5888671875,\n",
       "  'elevation_m': 73.0,\n",
       "  'channels': {'c01': {'channel_number': 1,\n",
       "    'component': 'e',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'i',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'c02': {'channel_number': 2,\n",
       "    'component': 'n',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'i',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'c03': {'channel_number': 3,\n",
       "    'component': 'v',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'i',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'}}}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suds_file_metadata(\"data/20251208_0500_HML1.seismosphere.sud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1bb40a65-0d06-4383-aa9e-4f8fe1743fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recorder': {'recorder_sensitivity_counts_per_volt': 2465210112.0,\n",
       "  'sensor_sensitivity_volts_per_unit': 1.0,\n",
       "  'atod_gain': 1,\n",
       "  'comment': SudsComment(refer=-32767, item=-32767, length=212, text='Battery Voltage=-1.0\\nSupply Current=-1.0\\nCharger Current=-1.0\\nTotal Bytes=-1\\nPercent Free=-1.0\\nTemperature=-999.0\\nSync=0.0\\nSensorA=CMG-6TD,Guralp, CMG-6T, 30 s - 100 Hz, 2400,Guralp\\nNormalizingFactor=1.00000e+00\\n', struct_offset=72594)},\n",
       " 'station': {'network': 'S1',\n",
       "  'station': 'AUSMG',\n",
       "  'location': '00',\n",
       "  'latitude_deg': -36.416099548339844,\n",
       "  'longitude_deg': 148.6083984375,\n",
       "  'elevation_m': 951.0,\n",
       "  'channels': {'HHZ': {'channel_number': 29,\n",
       "    'component': 'H',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'f',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'BHE': {'channel_number': 33,\n",
       "    'component': 'B',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'f',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'HHE': {'channel_number': 51,\n",
       "    'component': 'E',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'l',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'BHN': {'channel_number': 34,\n",
       "    'component': 'B',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'f',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'HHN': {'channel_number': 52,\n",
       "    'component': 'N',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'l',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'c03': {'channel_number': 10,\n",
       "    'component': 'v',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'i',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'BHZ': {'channel_number': 35,\n",
       "    'component': 'B',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'f',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'BH2': {'channel_number': 43,\n",
       "    'component': 'B',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'f',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'BH1': {'channel_number': 42,\n",
       "    'component': 'B',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'f',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'}}}}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suds_file_metadata(\"data/2025-12-05 0952 Mansfield Vic.dmx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12159ed7-6f38-4e18-a157-f8a9b19bef73",
   "metadata": {},
   "source": [
    "## metadata for multi -station suds\n",
    "\n",
    "Option A — Extend suds_file_metadata() to return a dict of stations\n",
    "\n",
    "Requires:\n",
    "\t•\tscanning all STATIONCOMP blocks\n",
    "\t•\tmapping DESCRIPTRACE traces to stations even if no STATIONCOMP exists\n",
    "\t•\tgracefully filling missing metadata\n",
    "\n",
    "Option B — Leave metadata as-is and focus on phases + waveforms first\n",
    "\n",
    "Because:\n",
    "\t•\tFor event files, STATIONCOMP may not exist for every station anyway.\n",
    "\t•\tPhase-picks (FEATURE structs) need decoding next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c0e07-1751-42b1-b6bb-bce995ff8073",
   "metadata": {},
   "source": [
    "# Phase arrivals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18cc7c-8268-4c1e-b1b7-973d0296bf68",
   "metadata": {},
   "source": [
    "Here are the five short, brutal-to-the-point dot points:\n",
    "\n",
    "\t1.\tPhase picks do exist in the SUDS file — the waveform viewer proves it — but we have not yet located a struct where the arrival time + phase code decode cleanly.\n",
    "    \n",
    "\t2.\tWe inspected struct ID 31 first (because that’s where the MLWM entries were), and it clearly contains station identifiers but no meaningful timing fields → not the arrival struct.\n",
    "    \n",
    "\t3.\tWe then inspected struct ID 10 (FEATURE), which should contain arrival times and phase codes according to the SUDS specification — but the bytes in your file do not decode cleanly into MS_TIME or the other FEATURE fields → either byte order / encoding differs, or this file uses a non-standard variant.\n",
    "    \n",
    "\t4.\tStruct ID 32 contains lists of stations participating in the event (like an association table), not picks — helpful context, but not the pick times themselves.\n",
    "    \n",
    "\t5.\tThe most likely situation now is: your file writes arrivals in a custom FEATURE-like struct but with different offsets or packing, meaning we need to reverse-engineer the true field layout directly from known arrival times (e.g., the MLWM i-P pick at 2025-12-05 09:52:09.40) and match them in the raw bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed383767-c4f4-46c1-a8d9-011eab8a7772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
