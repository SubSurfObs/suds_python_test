{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635f1123-701c-42ca-a758-ffd5fb37e7f7",
   "metadata": {},
   "source": [
    "# Converting PC-SUDS to MiniSEED — What We Actually Learned\n",
    "\n",
    "This project produced aims to provide a Python / Obspy nterface to PC-SUDS waveform data, as output by SRC recorders (e.g. kelunju EchoPro) and software (e.g. Waves). \n",
    "\n",
    "The functions in this notebook allow us to convert PC-SUDs to Obspoy streams, it also allow parsing of metadata into a nested dictionary. \n",
    "\n",
    "Accessing phase picks (if present) is a WIP. Phase arrival data is stored in the SUDS data file using SUDS_FEATURE structures.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. **SUDS File Structure (EchoPro / Gecko)**\n",
    "\n",
    "Every SUDS block begins with a **12-byte STRUCTAG**:\n",
    "\n",
    "| Bytes | Meaning |\n",
    "|------|---------|\n",
    "| 0 | `'S'` sync |\n",
    "| 1 | `'6'` machine ID |\n",
    "| 2–3 | struct ID (`uint16`) |\n",
    "| 4–7 | struct length (`uint32`) |\n",
    "| 8–11 | data length (`uint32`) |\n",
    "\n",
    "A full block looks like:\n",
    "\n",
    "```\n",
    "[STRUCTAG][STRUCT_BODY][DATA_BODY]\n",
    "```\n",
    "\n",
    "Based on multiple real-world files we’ve inspected — both raw `.seismosphere.sud` files and hand-picked `.pick.sud` variants — the following struct types occur consistently:\n",
    "\n",
    "| ID  | Struct Type      | Notes |\n",
    "|-----|------------------|-------|\n",
    "| **5**  | `STATIONCOMP`     | One per component. Always present. |\n",
    "| **7**  | `DESCRIPTRACE`    | One per component. Contains the trace + waveform samples. |\n",
    "| **20** | `COMMENT`          | One per component. Recorder metadata (SensorType, Sensitivity, OperatorTime, etc). |\n",
    "| **10** | `FEATURE`          | **Confirmed present when picks exist.** One FEATURE struct per pick (P/S/others). |\n",
    "| **31** | `DESC` / `DESCRIPHDR` | Appears after each STATIONCOMP. Contains calibration/scaling info. |\n",
    "| **32** | `FREQUENCY` / `FREQAMP` | Rare but observed at end of some files. Not related to picks. |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Where Metadata Actually Lives**\n",
    "\n",
    "### ✔ A. STATIONCOMP (ID = 5) — the main metadata block\n",
    "\n",
    "This contains:\n",
    "\n",
    "- latitude / longitude / elevation  \n",
    "- component code  \n",
    "- channel number  \n",
    "- sensor type (`v`, `a`, etc.)  \n",
    "- data type (`i`, `l`, `f`)  \n",
    "- data units  \n",
    "- polarity  \n",
    "- **A/D gain** (`atod_gain`)  \n",
    "- **start epoch** (effective time)  \n",
    "\n",
    "This is the **correct** source for station and channel identity.\n",
    "\n",
    "### Important  \n",
    "\n",
    "STATIONCOMP contains **A/D gain**, but *not* the recorder’s “counts per volt” calibration and *not* the sensor’s volts-per-unit sensitivity.  \n",
    "Those live outside the SUDS struct system.\n",
    "\n",
    "---\n",
    "\n",
    "### ✔ B. DESCRIPTRACE (ID = 7) — waveform header + waveform data\n",
    "\n",
    "We now know that the DESCRIPTRACE struct reliably contains:\n",
    "\n",
    "- `begintime` (converted from FLOAT64 → epoch ms → epoch seconds)  \n",
    "- `length` – exact number of samples  \n",
    "- `rate` – the **correct sampling rate**  \n",
    "- `datatype` – `'i'`, `'l'`, `'2'`, `'f'`  \n",
    "- waveform min/max values  \n",
    "- some gain correction floats  \n",
    "- number of clipped samples  \n",
    "- and then the **raw sample array**\n",
    "\n",
    "### Why DESCRIPTRACE is essential\n",
    "\n",
    "It provides **the correct:**\n",
    "\n",
    "- start time  \n",
    "- sample rate  \n",
    "- number of samples  \n",
    "\n",
    "and replaces the old “assume 60-second files” logic completely.\n",
    "\n",
    "---\n",
    "\n",
    "### ✔ C. COMMENT (ID = 20)\n",
    "\n",
    "EchoPro writes rich text blocks, e.h. :\n",
    "\n",
    "```\n",
    "DataLogger=Echo Pro\n",
    "Battery Voltage=10.76\n",
    "SensorA=Guralp CMG-6T-1\n",
    "SensorASerial=66532\n",
    "SensorB=Guralp CMG-5T-2g\n",
    "...\n",
    "```\n",
    "\n",
    "This is valuable operational metadata, but *not* response information.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Recorder & Sensor Sensitivity Are Not in Any SUDS Struct**\n",
    "\n",
    "This is the biggest practical insight from the reverse-engineering effort.\n",
    "\n",
    "| Quantity | Where it actually lives |\n",
    "|---------|--------------------------|\n",
    "| **Recorder sensitivity (counts per volt)** | float32 @ **absolute offset 156** |\n",
    "| **Sensor sensitivity (volts per unit)** | float32 @ **absolute offset 176** |\n",
    "| **Neither belongs to any SUDS struct** | ✔ correct |\n",
    "\n",
    "Examples found in real files:\n",
    "\n",
    "### Recorder sensitivity\n",
    "- Gecko: **419430.4**  \n",
    "- EchoPro: **838860.8**\n",
    "\n",
    "### Sensor sensitivity\n",
    "- HML1 accelerometer: **1010.0**  \n",
    "- LOCU velocimeter: **2400.0**  \n",
    "- STBK accelerometer: **750.0**\n",
    "\n",
    "These values were stable across many files.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Waveform Extraction (Final, Correct Logic)**\n",
    "\n",
    "We now use:\n",
    "\n",
    "- **DESCRIPTRACE.rate** → sample rate  \n",
    "- **DESCRIPTRACE.length** → number of samples  \n",
    "- **STATIONCOMP.start_epoch** → start time  \n",
    "- **STATIONCOMP.metadata** → channel identity  \n",
    "- **raw `len_data`** → bytes to read  \n",
    "- **datatype** → sample width  \n",
    "\n",
    "This is robust for all tested digitizers and file variants.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. where pick information actually lives\n",
    "\n",
    "All seismic arrival picks (P, S, I-P, etc.) are stored in **struct ID 10 (FEATURE)**.  \n",
    "Each FEATURE struct contains:\n",
    "\n",
    "- `obs_phase` — phase number encoded per SudsArrivalNumbers (P, S, etc.)\n",
    "- `onset`\n",
    "- `direction` (first motion)\n",
    "- `sig_noise`\n",
    "- `data_source` (`i`, `a`, `d`, etc.)\n",
    "- `tim_qual`\n",
    "- `amp_qual`\n",
    "- `ampunits`\n",
    "- `gain_range`\n",
    "- **`time` — arrival time, stored as MS_TIME (microseconds since epoch)**\n",
    "- `amplitude`\n",
    "- `period`\n",
    "- **`time_of_pick` — ST_TIME (ms since epoch)**\n",
    "- `pick_authority`\n",
    "- `pick_reader`\n",
    "\n",
    "This structure matches the SRC Java implementation exactly and is now the authoritative source for decoding picks.\n",
    "\n",
    "## 6. **Summary**\n",
    "\n",
    "- Modern digitizers produce a **minimal**, consistent subset of SUDS.\n",
    "- Only three struct types appear:\n",
    "  - **STATIONCOMP (ID 5)** — metadata  \n",
    "  - **DESCRIPTRACE (ID 7)** — waveform header + samples  \n",
    "  - **COMMENT (ID 20)** — text metadata  \n",
    "- Recorder and sensor sensitivities live **outside** all structs, at fixed offsets.\n",
    "- DESCRIPTRACE gives correct sample rate, correct sample count, and correct start time.\n",
    "- STATIONCOMP gives correct channel/station metadata.\n",
    "- Result: a fully functional, reliable PC-SUDS → MiniSEED converter in Python.\n",
    "\n",
    "This gives us a transparent, reproducible extraction workflow — and replaces the often-misleading Java code with a clean, modern implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cc2b2be-9f59-4049-bcd0-7c8a1eaec6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "from obspy import Trace, Stream, UTCDateTime\n",
    "from dataclasses import dataclass, field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2929fb47-c127-40bb-a960-da39c8ad53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. STATIONCOMP (unchanged from your \"locked in\" version)\n",
    "# ============================================================\n",
    "def parse_stationcomp_struct(raw, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Parse a SUDS_STATIONCOMP struct of length 108 bytes\n",
    "    (STATIDENT + STATIONCOMP guts + LONGIDENT) as per SRC Java.\n",
    "\n",
    "    Returns a metadata dict with keys:\n",
    "        network, station, location, channel_name, channel_number,\n",
    "        component_char, data_type, start_epoch, latitude, longitude,\n",
    "        elevation, atod_gain, sensor_type, data_units, polarity.\n",
    "    \"\"\"\n",
    "    if len(raw) != 108:\n",
    "        raise ValueError(f\"Expected 108 bytes for STATIONCOMP, got {len(raw)}\")\n",
    "\n",
    "    # --- STATIDENT (0–11) ---\n",
    "    statident = raw[0:12]\n",
    "    net_short = statident[0:4].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    sta_short = statident[4:9].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    comp_char = statident[9:10].decode(\"ascii\", errors=\"ignore\")\n",
    "\n",
    "    # --- STATIONCOMP guts (12–75, 64 bytes) ---\n",
    "    sc = raw[12:76]\n",
    "\n",
    "    lat = struct.unpack(\"<d\", sc[4:12])[0]\n",
    "    lon = struct.unpack(\"<d\", sc[12:20])[0]\n",
    "    elev = struct.unpack(\"<f\", sc[20:24])[0]\n",
    "\n",
    "    sensor_type = sc[31:32].decode(\"ascii\", errors=\"ignore\")\n",
    "    data_type = sc[32:33].decode(\"ascii\", errors=\"ignore\")   # 'i', 'l', '2', 'f', ...\n",
    "    data_units = sc[33:34].decode(\"ascii\", errors=\"ignore\")\n",
    "    polarity = sc[34:35].decode(\"ascii\", errors=\"ignore\")\n",
    "\n",
    "    channel_num = struct.unpack(\"<h\", sc[48:50])[0]\n",
    "    atod_gain = struct.unpack(\"<h\", sc[50:52])[0]\n",
    "\n",
    "    effective_val = struct.unpack(\"<i\", sc[52:56])[0]\n",
    "    # These files use seconds since Unix epoch\n",
    "    if 1_000_000_000 < effective_val < 2_200_000_000:\n",
    "        start_epoch = effective_val\n",
    "    else:\n",
    "        start_epoch = None\n",
    "\n",
    "    # --- LONGIDENT (76–107, 32 bytes) ---\n",
    "    li = raw[76:108]\n",
    "    net_long = li[0:8].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    sta_long = li[8:24].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "    comp_long = li[24:32].decode(\"ascii\", errors=\"ignore\").strip(\"\\x00\")\n",
    "\n",
    "    # Prefer LONGIDENT if present\n",
    "    network = net_long or net_short\n",
    "    station = sta_long or sta_short\n",
    "    channel_name = comp_long or comp_char  # 'CHE', 'CHZ', 'CHN', 'c01', …\n",
    "\n",
    "    # Location code: SUDS has none → use mapping, else '00'\n",
    "    if station_to_loc is not None and station in station_to_loc:\n",
    "        location = station_to_loc[station]\n",
    "    else:\n",
    "        location = \"00\"\n",
    "\n",
    "    return {\n",
    "        \"network\": network,\n",
    "        \"station\": station,\n",
    "        \"location\": location,\n",
    "        \"channel_name\": channel_name,\n",
    "        \"channel_number\": channel_num,\n",
    "        \"component_char\": comp_char,\n",
    "        \"data_type\": data_type,\n",
    "        \"start_epoch\": start_epoch,\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"elevation\": elev,\n",
    "        \"atod_gain\": atod_gain,\n",
    "        \"sensor_type\": sensor_type,\n",
    "        \"data_units\": data_units,\n",
    "        \"polarity\": polarity,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. DESCRIPTRACE parser (uses layout from Java + your hexdump)\n",
    "# ============================================================\n",
    "def _parse_descriptrace_struct(raw):\n",
    "    \"\"\"\n",
    "    Parse SUDS_DESCRIPTRACE \"guts\" *after* STATIDENT.\n",
    "\n",
    "    Layout inside the struct (after 12-byte STATIDENT):\n",
    "\n",
    "      double begintime       (8 bytes)  [seconds since epoch in your files]\n",
    "      short  localtime       (2)\n",
    "      char   datatype        (1)        'i', 'l', '2', 'f'\n",
    "      char   descriptor      (1)\n",
    "      short  digi_by         (2)\n",
    "      short  processed       (2)\n",
    "      int    length          (4)        # samples\n",
    "      float  rate            (4)        Hz\n",
    "      float  mindata         (4)\n",
    "      float  maxdata         (4)\n",
    "      float  avenoise        (4)\n",
    "      int    numclip         (4)\n",
    "      double time_correct    (8)\n",
    "      float  rate_correct    (4)\n",
    "\n",
    "    We only actually *need*:\n",
    "      begintime, datatype, length, rate\n",
    "    \"\"\"\n",
    "    if len(raw) < 12 + 8 + 2 + 1 + 1 + 2 + 2 + 4 + 4:\n",
    "        raise ValueError(\"DESCRIPTRACE struct too short\")\n",
    "\n",
    "    pos = 12  # skip STATIDENT\n",
    "\n",
    "    begintime_sec = struct.unpack_from(\"<d\", raw, pos)[0]\n",
    "    pos += 8\n",
    "\n",
    "    localtime = struct.unpack_from(\"<h\", raw, pos)[0]\n",
    "    pos += 2\n",
    "\n",
    "    datatype = struct.unpack_from(\"<c\", raw, pos)[0].decode(\"ascii\", errors=\"ignore\")\n",
    "    pos += 1\n",
    "\n",
    "    descriptor = struct.unpack_from(\"<c\", raw, pos)[0].decode(\"ascii\", errors=\"ignore\")\n",
    "    pos += 1\n",
    "\n",
    "    digi_by = struct.unpack_from(\"<h\", raw, pos)[0]\n",
    "    pos += 2\n",
    "\n",
    "    processed = struct.unpack_from(\"<h\", raw, pos)[0]\n",
    "    pos += 2\n",
    "\n",
    "    length = struct.unpack_from(\"<i\", raw, pos)[0]\n",
    "    pos += 4\n",
    "\n",
    "    rate = struct.unpack_from(\"<f\", raw, pos)[0]\n",
    "    pos += 4\n",
    "\n",
    "    # We could read the rest, but we don't need it here.\n",
    "\n",
    "    return {\n",
    "        \"begintime_sec\": begintime_sec,\n",
    "        \"datatype\": datatype,\n",
    "        \"length\": length,\n",
    "        \"rate\": rate,\n",
    "        \"localtime\": localtime,\n",
    "        \"digi_by\": digi_by,\n",
    "        \"processed\": processed,\n",
    "        \"descriptor\": descriptor,\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_instrument_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_INSTRUMENT (ID=10).\n",
    "    Returns dict with instrument response parameters.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_phasepick_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_PHS (ID=20).\n",
    "    Returns dict with station, channel, pick time, phase type, residual, etc.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_study_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_STUDY (ID=27).\n",
    "    Returns dict with study/project information.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_longident_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_LONGIDENT (ID=31).\n",
    "    Extended station ID.\n",
    "    \"\"\"\n",
    "    return {}\n",
    "\n",
    "\n",
    "def parse_hypo_struct(struct_bytes):\n",
    "    \"\"\"\n",
    "    Parse SUDS_HYPO (ID=32).\n",
    "    Returns dict:\n",
    "        {\n",
    "          \"origin_time\": ...,\n",
    "          \"latitude\": ...,\n",
    "          \"longitude\": ...,\n",
    "          \"depth_km\": ...,\n",
    "          \"magnitude\": ...,\n",
    "          \"errors\": {...}\n",
    "        }\n",
    "    \"\"\"\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96247111-90b4-42c0-b22f-cd4e14314c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e20f3b52-127a-431f-968a-e6c645ac6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 3. Waveform extraction — now using DESCRIPTRACE.rate/length\n",
    "# ============================================================\n",
    "def extract_waveforms_with_metadata(path, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Extract all waveforms from a SUDS file and attach metadata derived\n",
    "    from STATIONCOMP + DESCRIPTRACE.\n",
    "\n",
    "    Returns a list of dicts with keys:\n",
    "        network, station, location, channel,\n",
    "        start_epoch, samprate, latitude, longitude, elevation, data (np.float32).\n",
    "    \"\"\"\n",
    "    waves = []\n",
    "    meta = None  # last STATIONCOMP for pairing\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            tag_raw = f.read(12)\n",
    "            if len(tag_raw) < 12:\n",
    "                break\n",
    "\n",
    "            sync, mach, id_struct, len_struct, len_data = struct.unpack(\"<ccHII\", tag_raw)\n",
    "            if sync != b\"S\" or mach != b\"6\":\n",
    "                raise RuntimeError(f\"Bad SUDS tag sync/machine in {path}\")\n",
    "\n",
    "            struct_bytes = f.read(len_struct)\n",
    "            data_bytes = f.read(len_data) if len_data > 0 else b\"\"\n",
    "\n",
    "            # --- STATIONCOMP (metadata per channel) ---\n",
    "            if id_struct == 5:\n",
    "                try:\n",
    "                    meta = parse_stationcomp_struct(struct_bytes, station_to_loc=station_to_loc)\n",
    "                except Exception:\n",
    "                    meta = None\n",
    "                continue\n",
    "\n",
    "            # --- DESCRIPTRACE (waveform header + samples) ---\n",
    "            if id_struct == 7:\n",
    "                if meta is None:\n",
    "                    # No matching STATIONCOMP; skip waveform safely\n",
    "                    continue\n",
    "\n",
    "                # First try to parse DESCRIPTRACE header\n",
    "                desc = None\n",
    "                try:\n",
    "                    desc = _parse_descriptrace_struct(struct_bytes)\n",
    "                except Exception:\n",
    "                    desc = None\n",
    "\n",
    "                # Decide datatype\n",
    "                if desc is not None and desc[\"datatype\"] in (\"i\", \"l\", \"2\", \"f\"):\n",
    "                    dt = desc[\"datatype\"]\n",
    "                else:\n",
    "                    dt = meta[\"data_type\"]\n",
    "\n",
    "                # Map datatype -> bytes/sample, numpy dtype\n",
    "                if dt == \"i\":\n",
    "                    bps = 2\n",
    "                    np_dt = \"<i2\"\n",
    "                elif dt in (\"l\", \"2\"):\n",
    "                    bps = 4\n",
    "                    np_dt = \"<i4\"\n",
    "                elif dt == \"f\":\n",
    "                    bps = 4\n",
    "                    np_dt = \"<f4\"\n",
    "                else:\n",
    "                    # Unknown type: skip this waveform\n",
    "                    continue\n",
    "\n",
    "                total_samples = len(data_bytes) // bps\n",
    "\n",
    "                # Prefer DESCRIPTRACE.length if sane, else fall back to all bytes\n",
    "                if desc is not None and 0 < desc[\"length\"] <= total_samples:\n",
    "                    nsamp = desc[\"length\"]\n",
    "                else:\n",
    "                    nsamp = total_samples\n",
    "\n",
    "                # Prefer DESCRIPTRACE.rate if sane, else derive from nsamp/duration if you want\n",
    "                if desc is not None and desc[\"rate\"] > 0:\n",
    "                    samprate = float(desc[\"rate\"])\n",
    "                else:\n",
    "                    # Fallback: crude guess (1-minute files). You can tweak if needed.\n",
    "                    samprate = float(nsamp) / 60.0 if nsamp > 0 else 0.0\n",
    "\n",
    "                # Read exactly nsamp samples\n",
    "                nbytes = nsamp * bps\n",
    "                data = np.frombuffer(data_bytes[:nbytes], dtype=np_dt).astype(\"float32\")\n",
    "\n",
    "                waves.append({\n",
    "                # --- High-level waveform info ---\n",
    "                \"network\": meta[\"network\"],\n",
    "                \"station\": meta[\"station\"],\n",
    "                \"location\": meta[\"location\"],\n",
    "                \"channel\": meta[\"channel_name\"],     # ObsPy channel code\n",
    "                \"start_epoch\": meta[\"start_epoch\"],\n",
    "                \"samprate\": samprate,\n",
    "                \"data\": data,\n",
    "            \n",
    "                # --- Coordinates ---\n",
    "                \"latitude\": meta[\"latitude\"],\n",
    "                \"longitude\": meta[\"longitude\"],\n",
    "                \"elevation\": meta[\"elevation\"],\n",
    "            \n",
    "                # --- Channel-level metadata from STATIONCOMP ---\n",
    "                \"channel_number\": meta[\"channel_number\"],\n",
    "                \"component_char\": meta[\"component_char\"],\n",
    "                \"sensor_type\": meta[\"sensor_type\"],      # 'v', 'a', etc\n",
    "                \"data_type\": meta[\"data_type\"],          # 'i', 'l', '2', 'f'\n",
    "                \"data_units\": meta[\"data_units\"],        # usually 'd'\n",
    "                \"polarity\": meta[\"polarity\"],            # 'n' or 'r'\n",
    "                \"atod_gain\": meta[\"atod_gain\"],          # REAL value!\n",
    "            })\n",
    "\n",
    "            # All other struct types are ignored here\n",
    "\n",
    "    return waves\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Stream builder (unchanged interface)\n",
    "# ============================================================\n",
    "def suds_file_to_stream(path, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Parse a SUDS file and return an ObsPy Stream with one Trace per component.\n",
    "    \"\"\"\n",
    "    waves = extract_waveforms_with_metadata(path, station_to_loc=station_to_loc)\n",
    "\n",
    "    traces = []\n",
    "    for w in waves:\n",
    "        if w[\"start_epoch\"] is None:\n",
    "            raise RuntimeError(f\"No valid start_epoch found for file {path}\")\n",
    "\n",
    "        tr = Trace(\n",
    "            data=w[\"data\"],\n",
    "            header={\n",
    "                \"network\": w[\"network\"],\n",
    "                \"station\": w[\"station\"],\n",
    "                \"location\": w[\"location\"],\n",
    "                \"channel\": w[\"channel\"],\n",
    "                \"starttime\": UTCDateTime(w[\"start_epoch\"]),\n",
    "                \"sampling_rate\": w[\"samprate\"],\n",
    "            },\n",
    "        )\n",
    "        traces.append(tr)\n",
    "\n",
    "    return Stream(traces=traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe9b8f-5657-48b0-8cba-a73992bdb2eb",
   "metadata": {},
   "source": [
    "## test of read stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "baae7af6-706d-4c32-be3e-373169b646bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "VW.LOCU.00.CHE | 2025-12-09T04:50:00.000000Z - 2025-12-09T04:50:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.LOCU.00.CHN | 2025-12-09T04:50:00.000000Z - 2025-12-09T04:50:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.LOCU.00.CHZ | 2025-12-09T04:50:00.000000Z - 2025-12-09T04:50:59.996000Z | 250.0 Hz, 15000 samples\n"
     ]
    }
   ],
   "source": [
    "st = suds_file_to_stream(\"data/20251209_0450_LOCU.seismosphere.sud\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2994ef43-f41e-4900-828b-bb3e5c2f240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "VW.TRPU.00.CHE | 2025-12-08T05:00:00.000000Z - 2025-12-08T05:00:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.TRPU.00.CHZ | 2025-12-08T05:00:00.000000Z - 2025-12-08T05:00:59.996000Z | 250.0 Hz, 15000 samples\n",
      "VW.TRPU.00.CHN | 2025-12-08T05:00:00.000000Z - 2025-12-08T05:00:59.996000Z | 250.0 Hz, 15000 samples\n"
     ]
    }
   ],
   "source": [
    "st = suds_file_to_stream(\"data/20251208_0500_TRPU.seismosphere.sud\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38b0d91f-783b-4c77-9ffb-1f858beefd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.0\n",
      "250.0\n",
      "250.0\n"
     ]
    }
   ],
   "source": [
    "for tr in st:\n",
    "    print(tr.stats['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9acdd38d-b449-4258-9425-5aa0078409ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Trace(s) in Stream:\n",
      "\n",
      "S1.AUSMG.00.HHZ | 2025-12-05T09:51:59.000000Z - 2025-12-05T09:54:59.590000Z | 100.0 Hz, 18060 samples\n",
      "...\n",
      "(61 other traces)\n",
      "...\n",
      "OZ.FRTM.00.HHZ | 2025-12-05T09:52:00.000000Z - 2025-12-05T09:55:00.000000Z | 100.0 Hz, 18001 samples\n",
      "\n",
      "[Use \"print(Stream.__str__(extended=True))\" to print all Traces]\n"
     ]
    }
   ],
   "source": [
    "st = suds_file_to_stream(\"data/2025-12-05 0952 Mansfield Vic.dmx\")\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57f70137-f50a-40ea-b2e4-55f6fc5269ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "200.0\n",
      "100.0\n",
      "40.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "40.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "40.0\n",
      "200.0\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "for tr in st:\n",
    "    print(tr.stats['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2742c308-288a-4dae-bc49-adee7352b1b6",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "08ea2d61-2166-482b-803d-06f26138aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import struct\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class SudsComment:\n",
    "    refer: int\n",
    "    item: int\n",
    "    length: int\n",
    "    text: str\n",
    "    struct_offset: int\n",
    "\n",
    "def _decode_suds_comment(struct_buf: bytes, data_buf: bytes, offset: int) -> SudsComment:\n",
    "    refer, item, length, unused = struct.unpack(\"<hhhh\", struct_buf)\n",
    "    text = data_buf.decode(\"utf-8\", errors=\"replace\")\n",
    "    return SudsComment(refer, item, length, text, offset)\n",
    "\n",
    "def parse_suds_comments(path: str) -> List[SudsComment]:\n",
    "    COMMENT_ID = 20\n",
    "    comments = []\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        offset = 0\n",
    "        while True:\n",
    "            tag_raw = f.read(12)\n",
    "            if len(tag_raw) < 12:\n",
    "                break\n",
    "\n",
    "            sync, machine, id_struct, len_struct, len_data = struct.unpack(\"<ccHII\", tag_raw)\n",
    "            if sync != b\"S\" or machine != b\"6\":\n",
    "                break\n",
    "\n",
    "            struct_buf = f.read(len_struct)\n",
    "            data_buf = f.read(len_data) if len_data else b\"\"\n",
    "\n",
    "            if id_struct == COMMENT_ID:\n",
    "                comments.append(\n",
    "                    _decode_suds_comment(struct_buf, data_buf, offset)\n",
    "                )\n",
    "\n",
    "            offset += 12 + len_struct + len_data\n",
    "\n",
    "    return comments\n",
    "\n",
    "\n",
    "def read_float32_at_offset(path, offset):\n",
    "    \"\"\"\n",
    "    Read a little-endian float32 from absolute byte offset in a file.\n",
    "    Returns the float value or None if out of range.\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        f.seek(0, 2)\n",
    "        size = f.tell()\n",
    "        if offset + 4 > size:\n",
    "            return None\n",
    "        f.seek(offset)\n",
    "        data = f.read(4)\n",
    "    return struct.unpack(\"<f\", data)[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "bfaadf92-1340-4351-9b1b-6c7e4402a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suds_file_metadata(path, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Multi-station SUDS metadata.\n",
    "    Returns:\n",
    "    {\n",
    "      \"stations\":  { key → station metadata },\n",
    "      \"recorders\": { key → recorder metadata }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # ---- Global recorder fallbacks ----\n",
    "    global_recorder_sens = read_float32_at_offset(path, 156)\n",
    "    global_sensor_sens   = read_float32_at_offset(path, 176)\n",
    "\n",
    "    comments = parse_suds_comments(path)\n",
    "    comment  = comments[0] if comments else None\n",
    "\n",
    "    # ---- Waveform + STATIONCOMP parsing ----\n",
    "    waves = extract_waveforms_with_metadata(path, station_to_loc=station_to_loc)\n",
    "    if not waves:\n",
    "        raise RuntimeError(\"No STATIONCOMP/trace metadata found\")\n",
    "\n",
    "    from collections import defaultdict\n",
    "    grouped = defaultdict(list)\n",
    "\n",
    "    for w in waves:\n",
    "        key = f\"{w['network']}.{w['station']}.{w['location']}\"\n",
    "        grouped[key].append(w)\n",
    "\n",
    "    stations  = {}\n",
    "    recorders = {}\n",
    "\n",
    "    for key, ws in grouped.items():\n",
    "        w0 = ws[0]\n",
    "\n",
    "        # ---- station metadata ----\n",
    "        station_meta = {\n",
    "            \"network\": w0[\"network\"],\n",
    "            \"station\": w0[\"station\"],\n",
    "            \"location\": w0[\"location\"],\n",
    "            \"latitude_deg\": w0[\"latitude\"],\n",
    "            \"longitude_deg\": w0[\"longitude\"],\n",
    "            \"elevation_m\": w0[\"elevation\"],\n",
    "            \"channels\": {}\n",
    "        }\n",
    "\n",
    "        for w in ws:\n",
    "            station_meta[\"channels\"][w[\"channel\"]] = {\n",
    "                \"channel_number\": w[\"channel_number\"],\n",
    "                \"component\": w[\"component_char\"],\n",
    "                \"sensor_type\": w[\"sensor_type\"],\n",
    "                \"data_type\": w[\"data_type\"],\n",
    "                \"data_units\": w[\"data_units\"],\n",
    "                \"polarity\": w[\"polarity\"],\n",
    "            }\n",
    "\n",
    "        stations[key] = station_meta\n",
    "\n",
    "        # ---- recorder metadata (safe extraction) ----\n",
    "        recorder_sens = w0.get(\"recorder_sens\", global_recorder_sens)\n",
    "        sensor_sens   = w0.get(\"sensor_sens\",   global_sensor_sens)\n",
    "        atod_gain     = w0.get(\"atod_gain\",     None)\n",
    "\n",
    "        recorders[key] = {\n",
    "            \"recorder_sensitivity_counts_per_volt\": recorder_sens,\n",
    "            \"sensor_sensitivity_volts_per_unit\": sensor_sens,\n",
    "            \"atod_gain\": atod_gain,\n",
    "            \"comment\": comment,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"stations\": stations,\n",
    "        \"recorders\": recorders,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ad315-7794-42e3-b96e-547dc4b69e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "2fb77726-cd90-4f65-8231-ea39d3ea1e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_station = suds_file_metadata(\"data/20251208_0500_HML1.seismosphere.sud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a4fc9900-2d2b-41b2-9d35-31ede2c47ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stations', 'recorders'])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_station.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6d5b4c16-584f-49ab-a292-82739c3c8c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AB.HML1.00': {'network': 'AB',\n",
       "  'station': 'HML1',\n",
       "  'location': '00',\n",
       "  'latitude_deg': -34.403350830078125,\n",
       "  'longitude_deg': 138.5888671875,\n",
       "  'elevation_m': 73.0,\n",
       "  'channels': {'c01': {'channel_number': 1,\n",
       "    'component': 'e',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'i',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'c02': {'channel_number': 2,\n",
       "    'component': 'n',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'i',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'},\n",
       "   'c03': {'channel_number': 3,\n",
       "    'component': 'v',\n",
       "    'sensor_type': 'v',\n",
       "    'data_type': 'i',\n",
       "    'data_units': 'd',\n",
       "    'polarity': 'n'}}}}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_station['stations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12159ed7-6f38-4e18-a157-f8a9b19bef73",
   "metadata": {},
   "source": [
    "## metadata for multi -station suds\n",
    "\n",
    "* Working for stations, \n",
    "\n",
    "* but not for recorders (not sure how to access the station level info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1bb40a65-0d06-4383-aa9e-4f8fe1743fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_station = suds_file_metadata(\"data/2025-12-05 0952 Mansfield Vic.dmx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f39aa342-1acc-417b-864b-92b4ea06138e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network': 'S1',\n",
       " 'station': 'AUSMG',\n",
       " 'location': '00',\n",
       " 'latitude_deg': -36.416099548339844,\n",
       " 'longitude_deg': 148.6083984375,\n",
       " 'elevation_m': 951.0,\n",
       " 'channels': {'HHZ': {'channel_number': 6,\n",
       "   'component': 'Z',\n",
       "   'sensor_type': 'v',\n",
       "   'data_type': 'l',\n",
       "   'data_units': 'd',\n",
       "   'polarity': 'n'},\n",
       "  'HHE': {'channel_number': 4,\n",
       "   'component': 'E',\n",
       "   'sensor_type': 'v',\n",
       "   'data_type': 'l',\n",
       "   'data_units': 'd',\n",
       "   'polarity': 'n'},\n",
       "  'HHN': {'channel_number': 5,\n",
       "   'component': 'N',\n",
       "   'sensor_type': 'v',\n",
       "   'data_type': 'l',\n",
       "   'data_units': 'd',\n",
       "   'polarity': 'n'}}}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_station['stations']['S1.AUSMG.00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6851a6ad-5623-4348-ac12-568ce189a1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network': 'OZ',\n",
       " 'station': 'KORUM',\n",
       " 'location': '00',\n",
       " 'latitude_deg': -38.40644073486328,\n",
       " 'longitude_deg': 145.85084533691406,\n",
       " 'elevation_m': 354.0,\n",
       " 'channels': {'HHE': {'channel_number': 39,\n",
       "   'component': 'H',\n",
       "   'sensor_type': 'v',\n",
       "   'data_type': 'f',\n",
       "   'data_units': 'd',\n",
       "   'polarity': 'n'},\n",
       "  'HHN': {'channel_number': 40,\n",
       "   'component': 'H',\n",
       "   'sensor_type': 'v',\n",
       "   'data_type': 'f',\n",
       "   'data_units': 'd',\n",
       "   'polarity': 'n'},\n",
       "  'HHZ': {'channel_number': 41,\n",
       "   'component': 'H',\n",
       "   'sensor_type': 'v',\n",
       "   'data_type': 'f',\n",
       "   'data_units': 'd',\n",
       "   'polarity': 'n'}}}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_station['stations']['OZ.KORUM.00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "080d0e22-2353-4bfa-8b41-722f312fecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recorder_sensitivity_counts_per_volt': 2465210112.0,\n",
       " 'sensor_sensitivity_volts_per_unit': 1.0,\n",
       " 'atod_gain': 1,\n",
       " 'comment': SudsComment(refer=-32767, item=-32767, length=212, text='Battery Voltage=-1.0\\nSupply Current=-1.0\\nCharger Current=-1.0\\nTotal Bytes=-1\\nPercent Free=-1.0\\nTemperature=-999.0\\nSync=0.0\\nSensorA=CMG-6TD,Guralp, CMG-6T, 30 s - 100 Hz, 2400,Guralp\\nNormalizingFactor=1.00000e+00\\n', struct_offset=72594)}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_station['recorders']['AU.TOO.00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "cf861f48-482e-4ed8-952d-e4474448468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recorder_sensitivity_counts_per_volt': 2465210112.0,\n",
       " 'sensor_sensitivity_volts_per_unit': 1.0,\n",
       " 'atod_gain': 1,\n",
       " 'comment': SudsComment(refer=-32767, item=-32767, length=212, text='Battery Voltage=-1.0\\nSupply Current=-1.0\\nCharger Current=-1.0\\nTotal Bytes=-1\\nPercent Free=-1.0\\nTemperature=-999.0\\nSync=0.0\\nSensorA=CMG-6TD,Guralp, CMG-6T, 30 s - 100 Hz, 2400,Guralp\\nNormalizingFactor=1.00000e+00\\n', struct_offset=72594)}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_station['recorders']['OZ.HOPM.00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c0e07-1751-42b1-b6bb-bce995ff8073",
   "metadata": {},
   "source": [
    "multi_station['recorders']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2fef0870-3e3c-414f-8e67-0765d1d7738c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S1.AUSMG.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'AU.TOO.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.CCRM.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'AU.GEXS.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.CDNM.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.WAMB.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'M8.MOGAR.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'S1.AUSSC.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.TOT.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.KORUM.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'AB.BEGA.00': {'comment': None, 'atod_gain_values': [1]},\n",
       " 'OZ.FRTM.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'DU.S88P.00': {'comment': None, 'atod_gain_values': [1]},\n",
       " 'OZ.BUCHN.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'AU.MILA.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'AU.MLBS.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.DROM.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.BOGA.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.MLWM.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'S1.AUMAG.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'AU.GVL.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'OZ.HOPM.00': {'comment': None, 'atod_gain_values': [1, 1, 1]},\n",
       " 'DU.DAMM.00': {'comment': None, 'atod_gain_values': [1]}}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_station['recorders']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18cc7c-8268-4c1e-b1b7-973d0296bf68",
   "metadata": {},
   "source": [
    "# Phase arrivals\n",
    "\n",
    "\n",
    "## SUMMARY OF WHAT WORKED FOR A SINGLE P-WAVE PICK IN A SUDS FILE\n",
    "\n",
    "### strategy here was to  add a single pick, and compare files\n",
    "\n",
    "This kind of worked, but I wadsnlt abel to reprpoduce itm abd ChatGTP was just all over the plave\n",
    "\n",
    "\n",
    "1.\tIdentifying the FEATURE structures\n",
    "\n",
    "Your SUDS tag scanner correctly located the FEATURE structs (struct_id = 10).\n",
    "In the single-pick file there was exactly one FEATURE struct, at offset 121562 with length 80 bytes.\n",
    "These FEATURE blocks contain the arrival picks.\n",
    "\t\n",
    "2.\tExtracting the FEATURE payload\n",
    "\n",
    "The FEATURE struct consists of:\n",
    "\n",
    "* The statident block\n",
    "* The longident block\n",
    "* The actual FEATURE fields (the last 36 bytes)\n",
    "\n",
    "The last 36 bytes correspond exactly to the field layout implemented in the SRC Java class SUDS_FEATURE.\n",
    "\t\n",
    "    \n",
    "    3.\tField ordering from the SRC Java source\n",
    "\n",
    "The following order was confirmed as correct:\n",
    "\n",
    "obs_phase (short)\n",
    "onset (char)\n",
    "direction (char)\n",
    "sig_noise (short)\n",
    "data_source (char)\n",
    "tim_qual (char)\n",
    "amp_qual (char)\n",
    "ampunits (char)\n",
    "gain_range (short)\n",
    "time (double, arrival time in microseconds)\n",
    "amplitude (float)\n",
    "period (float)\n",
    "time_of_pick (int)\n",
    "pick_authority (short)\n",
    "pick_reader (short)\n",
    "\n",
    "This is exactly how the Java readGuts() method reads the struct.\n",
    "\t\n",
    "4.\tCorrect identification of the P-wave\n",
    "\n",
    "From the parsed bytes:\n",
    "obs_phase = 0x0032 = 50 decimal.\n",
    "Using SudsArrivalNumbers from the Java source, phase 50 corresponds to “P”.\n",
    "This matched the viewer, confirming we correctly extracted the pick type.\n",
    "\n",
    "5.\tCorrect extraction of the arrival time\n",
    "\n",
    "The “time” field (the double) contained a value that corresponded to:\n",
    "2025-12-09 04:50:25.425 UTC.\n",
    "You independently confirmed that this was the exact time you manually picked in the viewer.\n",
    "\n",
    "This proves:\n",
    "\n",
    "* We parsed the FEATURE struct correctly.\n",
    "* We interpreted MS_TIME correctly.\n",
    "* We extracted a valid, meaningful pick time.\n",
    "\n",
    "6.\tOther fields matched expectations\n",
    "\n",
    "data_source was correct for an interactive/manual pick.\n",
    "onset, amplitude, and period matched what the viewer produced for a simple P-only pick.\n",
    "Amplitude values were sentinel defaults because no amplitude measurement was made.\n",
    "\t\n",
    "7.\tConclusion for the single-pick case\n",
    "\n",
    "The workflow is validated:\n",
    "\n",
    "a) Locate struct_id = 10 blocks.\n",
    "b) Extract the 80-byte payload.\n",
    "c) Split off the final 36 bytes as the FEATURE content.\n",
    "d) Parse according to the Java SUDS_FEATURE field order.\n",
    "e) Convert obs_phase into a phase label.\n",
    "f) Convert arrival time into a UTC timestamp.\n",
    "g) All values match the viewer output.\n",
    "\n",
    "This provides a correct, stable baseline.\n",
    "\t8.\tWhat didn’t work (yet) in the multi-pick case\n",
    "\n",
    "\t•\tMultiple FEATURE blocks appear per station, but their meaning needs to be disentangled.\n",
    "\t•\tSome picks may not populate the arrival-time field, only the time_of_pick field.\n",
    "\t•\tS-wave picks may use the same station ident but a different offset; their relationship is not yet mapped.\n",
    "\t•\tAmplitude picks may not be encoded as FEATURE; they might live in a different struct type.\n",
    "\t•\tThe order of FEATURE structs may not correspond to P → S → amplitude, so you have to parse them by obs_phase, not by position.\n",
    "\n",
    "These are solvable, but need careful testing with your new multi-pick file.\n",
    "\n",
    "⸻"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a8f6e-c046-43f8-a481-47ef6655105c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2246674e-0708-45c4-bfd8-02277c597eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182511, 182552)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "before_path = Path(\"data/20251209_0450_LOCU.seismosphere.sud\")\n",
    "after_path  = Path(\"data/20251209_0450_LOCU.pick.sud\")\n",
    "\n",
    "b0 = before_path.read_bytes()\n",
    "b1 = after_path.read_bytes()\n",
    "\n",
    "len(b0), len(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e7684a9d-d8ee-42f1-8420-3d18267b12f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " [(21, 22),\n",
       "  (72, 73),\n",
       "  (114, 115),\n",
       "  (141, 142),\n",
       "  (148, 149),\n",
       "  (180, 183),\n",
       "  (240, 241),\n",
       "  (267, 268),\n",
       "  (295, 297),\n",
       "  (300, 301)])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_diff_spans(a: bytes, b: bytes, max_spans=50):\n",
    "    n = min(len(a), len(b))\n",
    "    spans = []\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if a[i] != b[i]:\n",
    "            start = i\n",
    "            while i < n and a[i] != b[i]:\n",
    "                i += 1\n",
    "            spans.append((start, i))\n",
    "            if len(spans) >= max_spans:\n",
    "                break\n",
    "        else:\n",
    "            i += 1\n",
    "    return spans\n",
    "\n",
    "diffs = find_diff_spans(b0, b1, max_spans=50)\n",
    "len(diffs), diffs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a919804e-0bd9-4fbb-aaaf-cc06f4612a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIFF BLOCK 0 @ 21–22 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "00000000  53 36 05 00 6c 00 00 00 00 00 00 00 56 57 00 00  |S6..l.......VW..|\n",
      "00000010  4c 4f 43 55 00 45 00 00 00 00 00 00 00 00 00 e0  |LOCU.E..........|\n",
      "00000020  ac 2e 43 c0 00 00 00 60 67 37 62 40 00 00 09 43  |..C....`g7b@...C|\n",
      "00000030  5f 00 4b 5f 80 01 5f 76 6c 64 6e 67 00 fe ff c6  |_.K_.._vldng....|\n",
      "00000040  00 00 00 4b 00 fe ff c6 01 00 01 00 78 aa 37 69  |...K........x.7i|\n",
      "00000050  00 00 00 00 00 00 00 00 56 57 00 00 00 00 00 00  |........VW......|\n",
      "00000060  4c 4f 43 55 00 00 00 00 00 00 00 00 00 00 00 00  |LOCU............|\n",
      "00000070  43 48 45 00 00 00 00 00 53 36 1f 00 72 00 00 00  |CHE.....S6..r...|\n",
      "--- AFTER ---\n",
      "00000000  53 36 05 00 6c 00 00 00 00 00 00 00 56 57 00 00  |S6..l.......VW..|\n",
      "00000010  4c 4f 43 55 00 4e 00 00 00 00 00 00 00 00 00 e0  |LOCU.N..........|\n",
      "00000020  ac 2e 43 c0 00 00 00 60 67 37 62 40 00 00 09 43  |..C....`g7b@...C|\n",
      "00000030  5f 00 4b 5f 80 01 5f 76 6c 64 6e 67 00 fe ff c6  |_.K_.._vldng....|\n",
      "00000040  00 00 00 4b 00 fe ff c6 02 00 01 00 78 aa 37 69  |...K........x.7i|\n",
      "00000050  00 00 00 00 00 00 00 00 56 57 00 00 00 00 00 00  |........VW......|\n",
      "00000060  4c 4f 43 55 00 00 00 00 00 00 00 00 00 00 00 00  |LOCU............|\n",
      "00000070  43 48 4e 00 00 00 00 00 53 36 1f 00 72 00 00 00  |CHN.....S6..r...|\n",
      "\n",
      "=== DIFF BLOCK 1 @ 72–73 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "00000028  67 37 62 40 00 00 09 43 5f 00 4b 5f 80 01 5f 76  |g7b@...C_.K_.._v|\n",
      "00000038  6c 64 6e 67 00 fe ff c6 00 00 00 4b 00 fe ff c6  |ldng.......K....|\n",
      "00000048  01 00 01 00 78 aa 37 69 00 00 00 00 00 00 00 00  |....x.7i........|\n",
      "00000058  56 57 00 00 00 00 00 00 4c 4f 43 55 00 00 00 00  |VW......LOCU....|\n",
      "00000068  00 00 00 00 00 00 00 00 43 48 45 00 00 00 00 00  |........CHE.....|\n",
      "00000078  53 36 1f 00 72 00 00 00 00 00 00 00 56 57 00 00  |S6..r.......VW..|\n",
      "00000088  4c 4f 43 55 00 45 00 00 bf 90 01 00 00 00 76 6c  |LOCU.E........vl|\n",
      "00000098  01 80 ff ff cd cc cc 48 00 fe ff c6 00 fe ff c6  |.......H........|\n",
      "--- AFTER ---\n",
      "00000028  67 37 62 40 00 00 09 43 5f 00 4b 5f 80 01 5f 76  |g7b@...C_.K_.._v|\n",
      "00000038  6c 64 6e 67 00 fe ff c6 00 00 00 4b 00 fe ff c6  |ldng.......K....|\n",
      "00000048  02 00 01 00 78 aa 37 69 00 00 00 00 00 00 00 00  |....x.7i........|\n",
      "00000058  56 57 00 00 00 00 00 00 4c 4f 43 55 00 00 00 00  |VW......LOCU....|\n",
      "00000068  00 00 00 00 00 00 00 00 43 48 4e 00 00 00 00 00  |........CHN.....|\n",
      "00000078  53 36 1f 00 72 00 00 00 00 00 00 00 56 57 00 00  |S6..r.......VW..|\n",
      "00000088  4c 4f 43 55 00 4e 00 00 bf 90 01 00 01 00 76 6c  |LOCU.N........vl|\n",
      "00000098  01 80 ff ff cd cc cc 48 00 fe ff c6 00 fe ff c6  |.......H........|\n",
      "\n",
      "=== DIFF BLOCK 2 @ 114–115 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "00000052  00 00 00 00 00 00 56 57 00 00 00 00 00 00 4c 4f  |......VW......LO|\n",
      "00000062  43 55 00 00 00 00 00 00 00 00 00 00 00 00 43 48  |CU............CH|\n",
      "00000072  45 00 00 00 00 00 53 36 1f 00 72 00 00 00 00 00  |E.....S6..r.....|\n",
      "00000082  00 00 56 57 00 00 4c 4f 43 55 00 45 00 00 bf 90  |..VW..LOCU.E....|\n",
      "00000092  01 00 00 00 76 6c 01 80 ff ff cd cc cc 48 00 fe  |....vl.......H..|\n",
      "000000a2  ff c6 00 fe ff c6 00 fe ff c6 00 fe ff c6 00 00  |................|\n",
      "000000b2  16 45 c2 ff 86 be 00 fe ff c6 00 fe ff c6 00 fe  |.E..............|\n",
      "000000c2  ff c6 78 aa 37 69 00 00 00 00 00 00 5f 5f 5f 5f  |..x.7i......____|\n",
      "--- AFTER ---\n",
      "00000052  00 00 00 00 00 00 56 57 00 00 00 00 00 00 4c 4f  |......VW......LO|\n",
      "00000062  43 55 00 00 00 00 00 00 00 00 00 00 00 00 43 48  |CU............CH|\n",
      "00000072  4e 00 00 00 00 00 53 36 1f 00 72 00 00 00 00 00  |N.....S6..r.....|\n",
      "00000082  00 00 56 57 00 00 4c 4f 43 55 00 4e 00 00 bf 90  |..VW..LOCU.N....|\n",
      "00000092  01 00 01 00 76 6c 01 80 ff ff cd cc cc 48 00 fe  |....vl.......H..|\n",
      "000000a2  ff c6 00 fe ff c6 00 fe ff c6 00 fe ff c6 00 00  |................|\n",
      "000000b2  16 45 dd 80 8c be 00 fe ff c6 00 fe ff c6 00 fe  |.E..............|\n",
      "000000c2  ff c6 78 aa 37 69 00 00 00 00 00 00 5f 5f 5f 5f  |..x.7i......____|\n",
      "\n",
      "=== DIFF BLOCK 3 @ 141–142 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "0000006d  00 00 00 43 48 45 00 00 00 00 00 53 36 1f 00 72  |...CHE.....S6..r|\n",
      "0000007d  00 00 00 00 00 00 00 56 57 00 00 4c 4f 43 55 00  |.......VW..LOCU.|\n",
      "0000008d  45 00 00 bf 90 01 00 00 00 76 6c 01 80 ff ff cd  |E........vl.....|\n",
      "0000009d  cc cc 48 00 fe ff c6 00 fe ff c6 00 fe ff c6 00  |..H.............|\n",
      "000000ad  fe ff c6 00 00 16 45 c2 ff 86 be 00 fe ff c6 00  |......E.........|\n",
      "000000bd  fe ff c6 00 fe ff c6 78 aa 37 69 00 00 00 00 00  |.......x.7i.....|\n",
      "000000cd  00 5f 5f 5f 5f 5f 00 00 00 56 57 00 00 00 00 00  |._____...VW.....|\n",
      "000000dd  00 4c 4f 43 55 00 00 00 00 00 00 00 00 00 00 00  |.LOCU...........|\n",
      "--- AFTER ---\n",
      "0000006d  00 00 00 43 48 4e 00 00 00 00 00 53 36 1f 00 72  |...CHN.....S6..r|\n",
      "0000007d  00 00 00 00 00 00 00 56 57 00 00 4c 4f 43 55 00  |.......VW..LOCU.|\n",
      "0000008d  4e 00 00 bf 90 01 00 01 00 76 6c 01 80 ff ff cd  |N........vl.....|\n",
      "0000009d  cc cc 48 00 fe ff c6 00 fe ff c6 00 fe ff c6 00  |..H.............|\n",
      "000000ad  fe ff c6 00 00 16 45 dd 80 8c be 00 fe ff c6 00  |......E.........|\n",
      "000000bd  fe ff c6 00 fe ff c6 78 aa 37 69 00 00 00 00 00  |.......x.7i.....|\n",
      "000000cd  00 5f 5f 5f 5f 5f 00 00 00 56 57 00 00 00 00 00  |._____...VW.....|\n",
      "000000dd  00 4c 4f 43 55 00 00 00 00 00 00 00 00 00 00 00  |.LOCU...........|\n",
      "\n",
      "=== DIFF BLOCK 4 @ 148–149 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "00000074  00 00 00 00 53 36 1f 00 72 00 00 00 00 00 00 00  |....S6..r.......|\n",
      "00000084  56 57 00 00 4c 4f 43 55 00 45 00 00 bf 90 01 00  |VW..LOCU.E......|\n",
      "00000094  00 00 76 6c 01 80 ff ff cd cc cc 48 00 fe ff c6  |..vl.......H....|\n",
      "000000a4  00 fe ff c6 00 fe ff c6 00 fe ff c6 00 00 16 45  |...............E|\n",
      "000000b4  c2 ff 86 be 00 fe ff c6 00 fe ff c6 00 fe ff c6  |................|\n",
      "000000c4  78 aa 37 69 00 00 00 00 00 00 5f 5f 5f 5f 5f 00  |x.7i......_____.|\n",
      "000000d4  00 00 56 57 00 00 00 00 00 00 4c 4f 43 55 00 00  |..VW......LOCU..|\n",
      "000000e4  00 00 00 00 00 00 00 00 00 00 43 48 45 00 00 00  |..........CHE...|\n",
      "--- AFTER ---\n",
      "00000074  00 00 00 00 53 36 1f 00 72 00 00 00 00 00 00 00  |....S6..r.......|\n",
      "00000084  56 57 00 00 4c 4f 43 55 00 4e 00 00 bf 90 01 00  |VW..LOCU.N......|\n",
      "00000094  01 00 76 6c 01 80 ff ff cd cc cc 48 00 fe ff c6  |..vl.......H....|\n",
      "000000a4  00 fe ff c6 00 fe ff c6 00 fe ff c6 00 00 16 45  |...............E|\n",
      "000000b4  dd 80 8c be 00 fe ff c6 00 fe ff c6 00 fe ff c6  |................|\n",
      "000000c4  78 aa 37 69 00 00 00 00 00 00 5f 5f 5f 5f 5f 00  |x.7i......_____.|\n",
      "000000d4  00 00 56 57 00 00 00 00 00 00 4c 4f 43 55 00 00  |..VW......LOCU..|\n",
      "000000e4  00 00 00 00 00 00 00 00 00 00 43 48 4e 00 00 00  |..........CHN...|\n",
      "\n",
      "=== DIFF BLOCK 5 @ 180–183 (len=3) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "00000094  00 00 76 6c 01 80 ff ff cd cc cc 48 00 fe ff c6  |..vl.......H....|\n",
      "000000a4  00 fe ff c6 00 fe ff c6 00 fe ff c6 00 00 16 45  |...............E|\n",
      "000000b4  c2 ff 86 be 00 fe ff c6 00 fe ff c6 00 fe ff c6  |................|\n",
      "000000c4  78 aa 37 69 00 00 00 00 00 00 5f 5f 5f 5f 5f 00  |x.7i......_____.|\n",
      "000000d4  00 00 56 57 00 00 00 00 00 00 4c 4f 43 55 00 00  |..VW......LOCU..|\n",
      "000000e4  00 00 00 00 00 00 00 00 00 00 43 48 45 00 00 00  |..........CHE...|\n",
      "000000f4  00 00 53 36 07 00 60 00 00 00 60 ea 00 00 56 57  |..S6..`...`...VW|\n",
      "00000104  00 00 4c 4f 43 55 00 45 00 00 00 00 00 9e ea 4d  |..LOCU.E.......M|\n",
      "--- AFTER ---\n",
      "00000094  01 00 76 6c 01 80 ff ff cd cc cc 48 00 fe ff c6  |..vl.......H....|\n",
      "000000a4  00 fe ff c6 00 fe ff c6 00 fe ff c6 00 00 16 45  |...............E|\n",
      "000000b4  dd 80 8c be 00 fe ff c6 00 fe ff c6 00 fe ff c6  |................|\n",
      "000000c4  78 aa 37 69 00 00 00 00 00 00 5f 5f 5f 5f 5f 00  |x.7i......_____.|\n",
      "000000d4  00 00 56 57 00 00 00 00 00 00 4c 4f 43 55 00 00  |..VW......LOCU..|\n",
      "000000e4  00 00 00 00 00 00 00 00 00 00 43 48 4e 00 00 00  |..........CHN...|\n",
      "000000f4  00 00 53 36 07 00 60 00 00 00 60 ea 00 00 56 57  |..S6..`...`...VW|\n",
      "00000104  00 00 4c 4f 43 55 00 4e 00 00 00 00 00 9e ea 4d  |..LOCU.N.......M|\n",
      "\n",
      "=== DIFF BLOCK 6 @ 240–241 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "000000d0  5f 5f 5f 00 00 00 56 57 00 00 00 00 00 00 4c 4f  |___...VW......LO|\n",
      "000000e0  43 55 00 00 00 00 00 00 00 00 00 00 00 00 43 48  |CU............CH|\n",
      "000000f0  45 00 00 00 00 00 53 36 07 00 60 00 00 00 60 ea  |E.....S6..`...`.|\n",
      "00000100  00 00 56 57 00 00 4c 4f 43 55 00 45 00 00 00 00  |..VW..LOCU.E....|\n",
      "00000110  00 9e ea 4d da 41 00 00 6c 5f 01 80 01 80 98 3a  |...M.A..l_.....:|\n",
      "00000120  00 00 00 00 7a 43 00 00 cc c3 00 80 cf 43 f6 68  |....zC.......C.h|\n",
      "00000130  8f c2 01 80 ff ff 00 00 00 00 00 00 00 00 00 00  |................|\n",
      "00000140  00 00 56 57 00 00 00 00 00 00 4c 4f 43 55 00 00  |..VW......LOCU..|\n",
      "--- AFTER ---\n",
      "000000d0  5f 5f 5f 00 00 00 56 57 00 00 00 00 00 00 4c 4f  |___...VW......LO|\n",
      "000000e0  43 55 00 00 00 00 00 00 00 00 00 00 00 00 43 48  |CU............CH|\n",
      "000000f0  4e 00 00 00 00 00 53 36 07 00 60 00 00 00 60 ea  |N.....S6..`...`.|\n",
      "00000100  00 00 56 57 00 00 4c 4f 43 55 00 4e 00 00 00 00  |..VW..LOCU.N....|\n",
      "00000110  00 9e ea 4d da 41 00 00 6c 5f 01 80 01 80 98 3a  |...M.A..l_.....:|\n",
      "00000120  00 00 00 00 7a 43 00 80 88 c3 00 80 96 43 85 eb  |....zC.......C..|\n",
      "00000130  c5 c0 01 80 ff ff 00 00 00 00 00 00 00 00 00 00  |................|\n",
      "00000140  00 00 56 57 00 00 00 00 00 00 4c 4f 43 55 00 00  |..VW......LOCU..|\n",
      "\n",
      "=== DIFF BLOCK 7 @ 267–268 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "000000eb  00 00 00 43 48 45 00 00 00 00 00 53 36 07 00 60  |...CHE.....S6..`|\n",
      "000000fb  00 00 00 60 ea 00 00 56 57 00 00 4c 4f 43 55 00  |...`...VW..LOCU.|\n",
      "0000010b  45 00 00 00 00 00 9e ea 4d da 41 00 00 6c 5f 01  |E.......M.A..l_.|\n",
      "0000011b  80 01 80 98 3a 00 00 00 00 7a 43 00 00 cc c3 00  |....:....zC.....|\n",
      "0000012b  80 cf 43 f6 68 8f c2 01 80 ff ff 00 00 00 00 00  |..C.h...........|\n",
      "0000013b  00 00 00 00 00 00 00 56 57 00 00 00 00 00 00 4c  |.......VW......L|\n",
      "0000014b  4f 43 55 00 00 00 00 00 00 00 00 00 00 00 00 43  |OCU............C|\n",
      "0000015b  48 45 00 00 00 00 00 12 00 00 00 20 00 00 00 05  |HE......... ....|\n",
      "--- AFTER ---\n",
      "000000eb  00 00 00 43 48 4e 00 00 00 00 00 53 36 07 00 60  |...CHN.....S6..`|\n",
      "000000fb  00 00 00 60 ea 00 00 56 57 00 00 4c 4f 43 55 00  |...`...VW..LOCU.|\n",
      "0000010b  4e 00 00 00 00 00 9e ea 4d da 41 00 00 6c 5f 01  |N.......M.A..l_.|\n",
      "0000011b  80 01 80 98 3a 00 00 00 00 7a 43 00 80 88 c3 00  |....:....zC.....|\n",
      "0000012b  80 96 43 85 eb c5 c0 01 80 ff ff 00 00 00 00 00  |..C.............|\n",
      "0000013b  00 00 00 00 00 00 00 56 57 00 00 00 00 00 00 4c  |.......VW......L|\n",
      "0000014b  4f 43 55 00 00 00 00 00 00 00 00 00 00 00 00 43  |OCU............C|\n",
      "0000015b  48 4e 00 00 00 00 00 e0 ff ff ff d7 ff ff ff e2  |HN..............|\n",
      "\n",
      "=== DIFF BLOCK 8 @ 295–297 (len=2) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "00000107  4f 43 55 00 45 00 00 00 00 00 9e ea 4d da 41 00  |OCU.E.......M.A.|\n",
      "00000117  00 6c 5f 01 80 01 80 98 3a 00 00 00 00 7a 43 00  |.l_.....:....zC.|\n",
      "00000127  00 cc c3 00 80 cf 43 f6 68 8f c2 01 80 ff ff 00  |......C.h.......|\n",
      "00000137  00 00 00 00 00 00 00 00 00 00 00 56 57 00 00 00  |...........VW...|\n",
      "00000147  00 00 00 4c 4f 43 55 00 00 00 00 00 00 00 00 00  |...LOCU.........|\n",
      "00000157  00 00 00 43 48 45 00 00 00 00 00 12 00 00 00 20  |...CHE......... |\n",
      "00000167  00 00 00 05 00 00 00 06 00 00 00 fe ff ff ff d1  |................|\n",
      "00000177  ff ff ff c7 ff ff ff e1 ff ff ff e5 ff ff ff ec  |................|\n",
      "--- AFTER ---\n",
      "00000107  4f 43 55 00 4e 00 00 00 00 00 9e ea 4d da 41 00  |OCU.N.......M.A.|\n",
      "00000117  00 6c 5f 01 80 01 80 98 3a 00 00 00 00 7a 43 00  |.l_.....:....zC.|\n",
      "00000127  80 88 c3 00 80 96 43 85 eb c5 c0 01 80 ff ff 00  |......C.........|\n",
      "00000137  00 00 00 00 00 00 00 00 00 00 00 56 57 00 00 00  |...........VW...|\n",
      "00000147  00 00 00 4c 4f 43 55 00 00 00 00 00 00 00 00 00  |...LOCU.........|\n",
      "00000157  00 00 00 43 48 4e 00 00 00 00 00 e0 ff ff ff d7  |...CHN..........|\n",
      "00000167  ff ff ff e2 ff ff ff be ff ff ff d8 ff ff ff fc  |................|\n",
      "00000177  ff ff ff d8 ff ff ff d2 ff ff ff d9 ff ff ff c8  |................|\n",
      "\n",
      "=== DIFF BLOCK 9 @ 300–301 (len=1) ===\n",
      "\n",
      "--- BEFORE ---\n",
      "0000010c  00 00 00 00 00 9e ea 4d da 41 00 00 6c 5f 01 80  |.......M.A..l_..|\n",
      "0000011c  01 80 98 3a 00 00 00 00 7a 43 00 00 cc c3 00 80  |...:....zC......|\n",
      "0000012c  cf 43 f6 68 8f c2 01 80 ff ff 00 00 00 00 00 00  |.C.h............|\n",
      "0000013c  00 00 00 00 00 00 56 57 00 00 00 00 00 00 4c 4f  |......VW......LO|\n",
      "0000014c  43 55 00 00 00 00 00 00 00 00 00 00 00 00 43 48  |CU............CH|\n",
      "0000015c  45 00 00 00 00 00 12 00 00 00 20 00 00 00 05 00  |E......... .....|\n",
      "0000016c  00 00 06 00 00 00 fe ff ff ff d1 ff ff ff c7 ff  |................|\n",
      "0000017c  ff ff e1 ff ff ff e5 ff ff ff ec ff ff ff f3 ff  |................|\n",
      "--- AFTER ---\n",
      "0000010c  00 00 00 00 00 9e ea 4d da 41 00 00 6c 5f 01 80  |.......M.A..l_..|\n",
      "0000011c  01 80 98 3a 00 00 00 00 7a 43 00 80 88 c3 00 80  |...:....zC......|\n",
      "0000012c  96 43 85 eb c5 c0 01 80 ff ff 00 00 00 00 00 00  |.C..............|\n",
      "0000013c  00 00 00 00 00 00 56 57 00 00 00 00 00 00 4c 4f  |......VW......LO|\n",
      "0000014c  43 55 00 00 00 00 00 00 00 00 00 00 00 00 43 48  |CU............CH|\n",
      "0000015c  4e 00 00 00 00 00 e0 ff ff ff d7 ff ff ff e2 ff  |N...............|\n",
      "0000016c  ff ff be ff ff ff d8 ff ff ff fc ff ff ff d8 ff  |................|\n",
      "0000017c  ff ff d2 ff ff ff d9 ff ff ff c8 ff ff ff e3 ff  |................|\n"
     ]
    }
   ],
   "source": [
    "def hexdump_block(buf: bytes, start: int, length: int = 128):\n",
    "    start = max(start, 0)\n",
    "    end = min(len(buf), start + length)\n",
    "    offset = start\n",
    "    while offset < end:\n",
    "        chunk = buf[offset:end if offset+16 > end else offset+16]\n",
    "        hex_part = \" \".join(f\"{b:02x}\" for b in chunk)\n",
    "        ascii_part = \"\".join(chr(b) if 32 <= b < 127 else \".\" for b in chunk)\n",
    "        print(f\"{offset:08x}  {hex_part:<47}  |{ascii_part}|\")\n",
    "        offset += 16\n",
    "\n",
    "for idx, (start, end) in enumerate(diffs[:10]):  # first few regions\n",
    "    print(f\"\\n=== DIFF BLOCK {idx} @ {start}–{end} (len={end-start}) ===\\n\")\n",
    "    context_start = start - 32\n",
    "    print(\"--- BEFORE ---\")\n",
    "    hexdump_block(b0, context_start, length=128)\n",
    "    print(\"--- AFTER ---\")\n",
    "    hexdump_block(b1, context_start, length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e2f88bca-a371-46b3-a98c-4b39b0f71e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tags(path):\n",
    "    \"\"\"\n",
    "    Scan a SUDS file and return all tag structures:\n",
    "    sync 'S', machine '6', struct_id, struct_length, data_length.\n",
    "    \"\"\"\n",
    "    tags = []\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    i = 0\n",
    "    n = len(data)\n",
    "\n",
    "    while i < n-12:\n",
    "        # Look for 'S6'\n",
    "        if data[i] == 0x53 and data[i+1] == 0x36:\n",
    "            \n",
    "            # Candidate tag location\n",
    "            try:\n",
    "                struct_id, struct_length, data_length = struct.unpack_from(\"<HII\", data, i+2)\n",
    "            except struct.error:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Sanity check: struct_length must be >= tag size\n",
    "            if 0 < struct_length < 50000:\n",
    "                tags.append({\n",
    "                    \"offset\": i,\n",
    "                    \"struct_id\": struct_id,\n",
    "                    \"struct_length\": struct_length,\n",
    "                    \"data_length\": data_length,\n",
    "                })\n",
    "\n",
    "                # Skip ahead: jump past tag + data (if declared sanely)\n",
    "                jump = 12 + struct_length + data_length\n",
    "                i += max(jump, 1)\n",
    "                continue\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6a57a185-39bf-4394-afd4-9c17fdaef4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'offset': 0, 'struct_id': 5, 'struct_length': 108, 'data_length': 0},\n",
       " {'offset': 120, 'struct_id': 31, 'struct_length': 114, 'data_length': 0},\n",
       " {'offset': 246, 'struct_id': 7, 'struct_length': 96, 'data_length': 60000},\n",
       " {'offset': 60354, 'struct_id': 20, 'struct_length': 8, 'data_length': 407},\n",
       " {'offset': 60781, 'struct_id': 5, 'struct_length': 108, 'data_length': 0},\n",
       " {'offset': 60901, 'struct_id': 31, 'struct_length': 114, 'data_length': 0},\n",
       " {'offset': 61027, 'struct_id': 7, 'struct_length': 96, 'data_length': 60000},\n",
       " {'offset': 121135, 'struct_id': 20, 'struct_length': 8, 'data_length': 407},\n",
       " {'offset': 121562, 'struct_id': 10, 'struct_length': 80, 'data_length': 0},\n",
       " {'offset': 121654, 'struct_id': 5, 'struct_length': 108, 'data_length': 0},\n",
       " {'offset': 121774, 'struct_id': 31, 'struct_length': 114, 'data_length': 0},\n",
       " {'offset': 121900, 'struct_id': 7, 'struct_length': 96, 'data_length': 60000},\n",
       " {'offset': 182008, 'struct_id': 20, 'struct_length': 8, 'data_length': 407},\n",
       " {'offset': 182435, 'struct_id': 10, 'struct_length': 80, 'data_length': 0},\n",
       " {'offset': 182527, 'struct_id': 10, 'struct_length': 80, 'data_length': 0},\n",
       " {'offset': 182619, 'struct_id': 32, 'struct_length': 45, 'data_length': 60}]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tags(\"data/20251209_0450_LOCU.pick.sud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "56051f9e-b007-4341-897d-b4c79121fc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 16)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_clean = list_tags(\"data/20251209_0450_LOCU.seismosphere.sud\")\n",
    "t_pick  = list_tags(\"data/20251209_0450_LOCU.pick.sud\")\n",
    "\n",
    "len(t_clean), len(t_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3c4c4cb7-f606-42b1-ab93-8ff70ef503c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60781,\n",
       " 60901,\n",
       " 61027,\n",
       " 121135,\n",
       " 121562,\n",
       " 121654,\n",
       " 121774,\n",
       " 121900,\n",
       " 182008,\n",
       " 182435,\n",
       " 182527,\n",
       " 182619]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_offsets = {t[\"offset\"] for t in t_clean}\n",
    "pick_offsets  = {t[\"offset\"] for t in t_pick}\n",
    "\n",
    "new_offsets = sorted(pick_offsets - clean_offsets)\n",
    "new_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "afdd4a8f-36aa-412c-8768-aa6793d1de62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'offset': 60781, 'struct_id': 5, 'struct_length': 108, 'data_length': 0},\n",
       " {'offset': 60901, 'struct_id': 31, 'struct_length': 114, 'data_length': 0},\n",
       " {'offset': 61027, 'struct_id': 7, 'struct_length': 96, 'data_length': 60000},\n",
       " {'offset': 121135, 'struct_id': 20, 'struct_length': 8, 'data_length': 407},\n",
       " {'offset': 121562, 'struct_id': 10, 'struct_length': 80, 'data_length': 0},\n",
       " {'offset': 121654, 'struct_id': 5, 'struct_length': 108, 'data_length': 0},\n",
       " {'offset': 121774, 'struct_id': 31, 'struct_length': 114, 'data_length': 0},\n",
       " {'offset': 121900, 'struct_id': 7, 'struct_length': 96, 'data_length': 60000},\n",
       " {'offset': 182008, 'struct_id': 20, 'struct_length': 8, 'data_length': 407},\n",
       " {'offset': 182435, 'struct_id': 10, 'struct_length': 80, 'data_length': 0},\n",
       " {'offset': 182527, 'struct_id': 10, 'struct_length': 80, 'data_length': 0},\n",
       " {'offset': 182619, 'struct_id': 32, 'struct_length': 45, 'data_length': 60}]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tag for tag in t_pick if tag[\"offset\"] in new_offsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b9cbf7e5-98bb-4f25-889c-210df3a7cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_struct10_feature(data, offset):\n",
    "    body = data[offset+12 : offset+12+80]\n",
    "    \n",
    "    statident = body[:16]\n",
    "    rest = body[16:]\n",
    "\n",
    "    fields = struct.unpack(\"<h c c h c c c c h d f f i h h\", rest)\n",
    "\n",
    "    return {\n",
    "        \"network\": statident[0:2].decode(\"ascii\", \"ignore\"),\n",
    "        \"station\": statident[2:7].decode(\"ascii\", \"ignore\"),\n",
    "        \"component\": chr(statident[7]),\n",
    "        \"obs_phase\": fields[0],\n",
    "        \"onset\": fields[1].decode(),\n",
    "        \"direction\": fields[2].decode(),\n",
    "        \"sig_noise\": fields[3],\n",
    "        \"data_source\": fields[4].decode(),\n",
    "        \"tim_qual\": fields[5],\n",
    "        \"amp_qual\": fields[6],\n",
    "        \"ampunits\": fields[7],\n",
    "        \"gain_range\": fields[8],\n",
    "        \"arrival_time\": fields[9],    # MS_TIME\n",
    "        \"amplitude\": fields[10],\n",
    "        \"period\": fields[11],\n",
    "        \"time_of_pick\": fields[12],   # ST_TIME\n",
    "        \"pick_authority\": fields[13],\n",
    "        \"pick_reader\": fields[14],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "48be3e0d-8376-4cba-9e1b-2bcd5c7b55e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HEADER (12 bytes) ===\n",
      "0a 53 65 6e 73 6f 72 41 53 65 72 69\n",
      "\n",
      "=== PAYLOAD (struct_id 10, length 80) ===\n",
      "61 6c 3d 75 6e 6b 6e 6f 77 6e 0a 46 69 6c 74 65 72 20 30 2e 30 20 31 32 35 2e 30 0a 4e 6f 72 6d 61 6c 69 7a 69 6e 67 46 61 63 74 6f 72 3d 31 2e 30 30 30 30 30 65 2b 30 30 0a 53 65 6e 73 6f 72 53 65 6e 73 69 74 69 76 69 74 79 3d 30 2e 30 0a\n"
     ]
    }
   ],
   "source": [
    "import binascii\n",
    "\n",
    "def read_struct10(data, offset, struct_length=80):\n",
    "    header = data[offset : offset+12]\n",
    "    payload = data[offset+12 : offset+12+struct_length]\n",
    "\n",
    "    print(\"=== HEADER (12 bytes) ===\")\n",
    "    print(binascii.hexlify(header, sep=\" \").decode())\n",
    "\n",
    "    print(\"\\n=== PAYLOAD (struct_id 10, length 80) ===\")\n",
    "    print(binascii.hexlify(payload, sep=\" \").decode())\n",
    "\n",
    "    return payload\n",
    "\n",
    "# Load file\n",
    "with open(\"data/20251209_0450_LOCU.pick.sud\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "payload = read_struct10(data, 182343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8a783442-d8f8-4603-90e7-d031bb554cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HEADER (12 bytes) ===\n",
      "53 36 0a 00 50 00 00 00 00 00 00 00\n",
      "\n",
      "=== PAYLOAD (struct_id 10, length 80) ===\n",
      "30 00 00 00 4c 4f 43 55 00 45 00 00 32 00 20 20 00 00 20 33 30 20 00 00 33 33 5b a4 ea 4d da 41 00 00 00 00 00 00 00 00 17 b9 38 69 5f 5f 5f 5f 30 00 00 00 00 00 00 00 4c 4f 43 55 00 00 00 00 00 00 00 00 00 00 00 00 43 48 45 00 00 00 00 00\n"
     ]
    }
   ],
   "source": [
    "payload = read_struct10(data, 182343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cfa523f3-041c-44e1-9ac8-e9ab7b213261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def read_feature_at_tag(path, tag):\n",
    "    \"\"\"\n",
    "    Read a single SUDS_FEATURE (struct_id=10) and print the raw arrival time.\n",
    "    Assumes `tag` is one of the dicts returned by your list_tags().\n",
    "    \"\"\"\n",
    "    assert tag[\"struct_id\"] == 10, \"Not a FEATURE struct\"\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        # 1. Seek to the start of this struct\n",
    "        f.seek(tag[\"offset\"])\n",
    "\n",
    "        # 2. Read the 12-byte SUDS_STRUCTAG header (\"S6\", id, lengths, etc.)\n",
    "        header = f.read(12)\n",
    "        magic, struct_id, struct_len = struct.unpack(\"<2sH I\", header[:8])\n",
    "        # (You can print these if you want to sanity-check)\n",
    "\n",
    "        # 3. Read the FEATURE payload\n",
    "        payload_len = struct_len  # in your file this is 80\n",
    "        payload = f.read(payload_len)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # NOW WE ARE IN THE FEATURE PAYLOAD\n",
    "    # -------------------------------------------------------\n",
    "    #\n",
    "    # The tricky bit is the NamedSuds \"name\" blob at the front.\n",
    "    # The *safe* thing to do is:\n",
    "    #   - scan the payload for the first place where the FEATURE body\n",
    "    #     looks valid: obs_phase (short), some chars, then a plausible double.\n",
    "    #\n",
    "    # This keeps us honest without assuming too much about NamedSuds.\n",
    "\n",
    "    def try_parse_feature_body(start):\n",
    "        body = payload[start:start+36]\n",
    "        if len(body) < 36:\n",
    "            return None\n",
    "\n",
    "        obs_phase, onset, direction, sig_noise, \\\n",
    "        data_source, tim_qual, amp_qual, ampunits, \\\n",
    "        gain_range, time_val, amplitude, period, \\\n",
    "        time_of_pick, pick_authority, pick_reader = struct.unpack(\n",
    "            \"<hcc h cccc h d f f i h h\", body\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"start\": start,\n",
    "            \"obs_phase\": obs_phase,\n",
    "            \"onset\": onset.decode(\"ascii\", \"ignore\"),\n",
    "            \"direction\": direction.decode(\"ascii\", \"ignore\"),\n",
    "            \"data_source\": data_source.decode(\"ascii\", \"ignore\"),\n",
    "            \"tim_qual\": tim_qual.decode(\"ascii\", \"ignore\"),\n",
    "            \"amp_qual\": amp_qual.decode(\"ascii\", \"ignore\"),\n",
    "            \"ampunits\": ampunits.decode(\"ascii\", \"ignore\"),\n",
    "            \"sig_noise\": sig_noise,\n",
    "            \"gain_range\": gain_range,\n",
    "            \"time\": time_val,\n",
    "            \"amplitude\": amplitude,\n",
    "            \"period\": period,\n",
    "            \"time_of_pick_raw\": time_of_pick,\n",
    "            \"pick_authority_raw\": pick_authority,\n",
    "            \"pick_reader_raw\": pick_reader,\n",
    "        }\n",
    "\n",
    "    # Brute-force: slide over the payload and look for a *sane* time field\n",
    "    candidates = []\n",
    "    for start in range(0, len(payload) - 36):\n",
    "        try:\n",
    "            feat = try_parse_feature_body(start)\n",
    "        except struct.error:\n",
    "            continue\n",
    "        if feat is None:\n",
    "            continue\n",
    "\n",
    "        # Very weak sanity check: time should be non-zero and not NaN/inf\n",
    "        t = feat[\"time\"]\n",
    "        if 0 < abs(t) < 1e18:\n",
    "            candidates.append(feat)\n",
    "\n",
    "    print(f\"Found {len(candidates)} candidate FEATURE bodies in this payload\")\n",
    "    for feat in candidates:\n",
    "        print(\"---- CANDIDATE ----\")\n",
    "        print(f\"start offset in payload: {feat['start']}\")\n",
    "        print(f\"obs_phase: {feat['obs_phase']}\")\n",
    "        print(f\"onset: {feat['onset']!r}, direction: {feat['direction']!r}\")\n",
    "        print(f\"data_source: {feat['data_source']!r}\")\n",
    "        print(f\"time (raw double): {feat['time']}\")\n",
    "        print(f\"time_of_pick (raw int): {feat['time_of_pick_raw']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cada821d-44c4-457a-b55d-98f92ca1efa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 candidate FEATURE bodies in this payload\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 0\n",
      "obs_phase: 48\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: 'C'\n",
      "time (raw double): 1.9446925070625807e-62\n",
      "time_of_pick (raw int): 1104825834\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 1\n",
      "obs_phase: 0\n",
      "onset: '\\x00', direction: 'L'\n",
      "data_source: 'U'\n",
      "time (raw double): 1.6516672368077707e-76\n",
      "time_of_pick (raw int): 4315725\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 2\n",
      "obs_phase: 0\n",
      "onset: 'L', direction: 'O'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 1.2082293478490017e-153\n",
      "time_of_pick (raw int): 16858\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 3\n",
      "obs_phase: 19456\n",
      "onset: 'O', direction: 'C'\n",
      "data_source: 'E'\n",
      "time (raw double): 4.502514859642823e-308\n",
      "time_of_pick (raw int): 65\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 4\n",
      "obs_phase: 20300\n",
      "onset: 'C', direction: 'U'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 1.74856690950336e-310\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 5\n",
      "obs_phase: 17231\n",
      "onset: 'U', direction: '\\x00'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 4.861879927037202e-63\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 6\n",
      "obs_phase: 21827\n",
      "onset: '\\x00', direction: 'E'\n",
      "data_source: '2'\n",
      "time (raw double): 4.618644617916342e-62\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 8\n",
      "obs_phase: 17664\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: ' '\n",
      "time (raw double): -1.4968931092454652e-133\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 12\n",
      "obs_phase: 50\n",
      "onset: ' ', direction: ' '\n",
      "data_source: ' '\n",
      "time (raw double): 1765255825.425\n",
      "time_of_pick (raw int): 1765325079\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 13\n",
      "obs_phase: 8192\n",
      "onset: ' ', direction: '\\x00'\n",
      "data_source: '3'\n",
      "time (raw double): 1.9861845235203828e-307\n",
      "time_of_pick (raw int): 1600731321\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 14\n",
      "obs_phase: 8224\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: '0'\n",
      "time (raw double): 3.5773250898133e-310\n",
      "time_of_pick (raw int): 1600088376\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 15\n",
      "obs_phase: 32\n",
      "onset: '\\x00', direction: ' '\n",
      "data_source: ' '\n",
      "time (raw double): 1.397392613207e-312\n",
      "time_of_pick (raw int): 1600085865\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 16\n",
      "obs_phase: 0\n",
      "onset: ' ', direction: '3'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 5.45856489e-315\n",
      "time_of_pick (raw int): 1600085855\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 17\n",
      "obs_phase: 8192\n",
      "onset: '3', direction: '0'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 2.1322515e-317\n",
      "time_of_pick (raw int): 811556703\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 18\n",
      "obs_phase: 13088\n",
      "onset: '0', direction: ' '\n",
      "data_source: '3'\n",
      "time (raw double): 8.329e-320\n",
      "time_of_pick (raw int): 3170143\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 19\n",
      "obs_phase: 12339\n",
      "onset: ' ', direction: '\\x00'\n",
      "data_source: '3'\n",
      "time (raw double): 3.2e-322\n",
      "time_of_pick (raw int): 12383\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 21\n",
      "obs_phase: 32\n",
      "onset: '\\x00', direction: '3'\n",
      "data_source: ''\n",
      "time (raw double): 6.688871304346933e-198\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 22\n",
      "obs_phase: 0\n",
      "onset: '3', direction: '3'\n",
      "data_source: ''\n",
      "time (raw double): -1.1074097180226606e-33\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 23\n",
      "obs_phase: 13056\n",
      "onset: '3', direction: '['\n",
      "data_source: 'M'\n",
      "time (raw double): 1.8875500538328882e-35\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 29\n",
      "obs_phase: -9651\n",
      "onset: 'A', direction: '\\x00'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 1.0837544854244015e-75\n",
      "time_of_pick (raw int): 5587791\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 30\n",
      "obs_phase: 16858\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 9.107532705169262e-308\n",
      "time_of_pick (raw int): 21827\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 31\n",
      "obs_phase: 65\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 2.62774644269793e-310\n",
      "time_of_pick (raw int): 85\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 32\n",
      "obs_phase: 0\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 1.026463454177e-312\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 33\n",
      "obs_phase: 0\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 4.009622866e-315\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 34\n",
      "obs_phase: 0\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: '\\x17'\n",
      "time (raw double): 1.5662587e-317\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 35\n",
      "obs_phase: 0\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: ''\n",
      "time (raw double): 6.118e-320\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 36\n",
      "obs_phase: 0\n",
      "onset: '\\x00', direction: '\\x00'\n",
      "data_source: '8'\n",
      "time (raw double): 2.37e-322\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 39\n",
      "obs_phase: 5888\n",
      "onset: '', direction: '8'\n",
      "data_source: '_'\n",
      "time (raw double): 1.7618574323482624e+16\n",
      "time_of_pick (raw int): 0\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 41\n",
      "obs_phase: 14521\n",
      "onset: 'i', direction: '_'\n",
      "data_source: '_'\n",
      "time (raw double): 4.73115868597172e-307\n",
      "time_of_pick (raw int): 1124073472\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 42\n",
      "obs_phase: 26936\n",
      "onset: '_', direction: '_'\n",
      "data_source: '0'\n",
      "time (raw double): 4.6317459424848e-310\n",
      "time_of_pick (raw int): 1212350464\n",
      "---- CANDIDATE ----\n",
      "start offset in payload: 43\n",
      "obs_phase: 24425\n",
      "onset: '_', direction: '_'\n",
      "data_source: '\\x00'\n",
      "time (raw double): 1.809275758783e-312\n",
      "time_of_pick (raw int): 1162363648\n"
     ]
    }
   ],
   "source": [
    "feature_tag = {\n",
    "    \"offset\": 182343,\n",
    "    \"struct_id\": 10,\n",
    "    \"struct_length\": 80,\n",
    "    \"data_length\": 0,\n",
    "}\n",
    "\n",
    "read_feature_at_tag(\"data/20251209_0450_LOCU.pick.sud\", feature_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3ca31c81-d25e-43c6-8203-d384e40b5538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-09 04:50:25.425000+00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "arrival = 1765255825.425  # your value from the FEATURE\n",
    "\n",
    "dt = datetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=arrival)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601b1e5-e8ff-43a3-8352-2fa01c0581ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=arrival)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56489a1-28ce-44c8-b1dd-1456c4a1af7e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42146d9b-1cd1-47e0-a264-9e503e5aa211",
   "metadata": {},
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d735e185-5585-4708-b32c-8fa3a7c7ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suds_file_metadata(path, station_to_loc=None):\n",
    "    \"\"\"\n",
    "    Clean consolidated metadata structure.\n",
    "    Returns:\n",
    "      {\n",
    "        \"recorder\": { ... },\n",
    "        \"station\": { ... }\n",
    "      }\n",
    "    \"\"\"\n",
    "    # ---- 1. Recorder-level values ----\n",
    "    recorder_sens = read_float32_at_offset(path, 156)\n",
    "    sensor_sens   = read_float32_at_offset(path, 176)\n",
    "    comments      = parse_suds_comments(path)\n",
    "    comment       = comments[0] if comments else None\n",
    "\n",
    "    # ---- 2. Station + channel metadata ----\n",
    "    waves = extract_waveforms_with_metadata(path, station_to_loc=station_to_loc)\n",
    "\n",
    "    if not waves:\n",
    "        raise RuntimeError(\"No STATIONCOMP/trace metadata found\")\n",
    "\n",
    "    # All channels have same station coordinates\n",
    "    w0 = waves[0]\n",
    "\n",
    "    station_meta = {\n",
    "        \"network\": w0[\"network\"],\n",
    "        \"station\": w0[\"station\"],\n",
    "        \"location\": w0[\"location\"],\n",
    "        \"latitude_deg\": w0[\"latitude\"],\n",
    "        \"longitude_deg\": w0[\"longitude\"],\n",
    "        \"elevation_m\": w0[\"elevation\"],\n",
    "        \"channels\": {}\n",
    "    }\n",
    "\n",
    "    # Move atod_gain to recorder-level\n",
    "    atod_gain = w0[\"atod_gain\"]\n",
    "\n",
    "    for w in waves:\n",
    "        station_meta[\"channels\"][w[\"channel\"]] = {\n",
    "            \"channel_number\": w[\"channel_number\"],\n",
    "            \"component\": w[\"component_char\"],\n",
    "            \"sensor_type\": w[\"sensor_type\"],\n",
    "            \"data_type\": w[\"data_type\"],\n",
    "            \"data_units\": w[\"data_units\"],\n",
    "            \"polarity\": w[\"polarity\"],\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"recorder\": {\n",
    "            \"recorder_sensitivity_counts_per_volt\": recorder_sens,\n",
    "            \"sensor_sensitivity_volts_per_unit\": sensor_sens,\n",
    "            \"atod_gain\": atod_gain,\n",
    "            \"comment\": comment,\n",
    "        },\n",
    "        \"station\": station_meta,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ee4cb-2ab6-4085-b227-6c8d89a9c66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
